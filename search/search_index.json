{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":""},{"location":"#coppafish","title":"Coppafish","text":"<p>Coppafish is an open source data analysis software for COmbinatorial Padlock-Probe-Amplified Fluorescence In Situ Hybridization (coppafish) datasets. A series of 3D microscope images are arranged into tiles, rounds and channels. For each sequencing round, every considered gene is fluoresced by a dye. By the end of all rounds, each gene has a unique, barcode-like sequence of dyes, called the gene code. For more details about coppafish's methodology, see the overview. See installation on how to install our software, and usage to run coppafish on your dataset. Some vocabulary might be unfamiliar, please see the glossary for reference.</p> Gene calling on a tile."},{"location":"#installation","title":"Installation","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Windows or Linux operating system. MacOS is not tested.</li> <li>At least 48GB of RAM for tile sizes <code>58x2048x2048</code>.</li> <li>Python version 3.9 or 3.10.</li> <li>Git.</li> </ul>"},{"location":"#environment","title":"Environment","text":"<p>Install coppafish software from within an environment. This can be a <code>venv</code> or <code>conda</code> (recommended) environment.</p>"},{"location":"#conda","title":"Conda","text":"<p>For <code>conda</code>, build an environment by doing: <pre><code>conda create -n coppafish python=3.10\nconda activate coppafish\n</code></pre></p>"},{"location":"#install","title":"Install","text":"<p>Our latest coppafish release can be cloned locally <pre><code>git clone --depth 1 https://github.com/reillytilbury/coppafish\n</code></pre></p> <p>install package dependencies and coppafish by <pre><code>cd coppafish\npython -m pip install --upgrade pip\npython -m pip install -r requirements.txt\npython -m pip install .\n</code></pre></p>"},{"location":"#updating","title":"Updating","text":"<p>Coppafish will not automatically install updates, but you will see a warning at the start of a pipeline if a new online version is available.</p> <p>If you already have the source code downloaded, navigate inside of the <code>coppafish</code> directory, then <code>git pull</code>  the latest code changes. Then, follow the install steps again, excluding the <code>git clone</code> command,  while inside your coppafish environment.</p> <p>If you do not have the source code downloaded anymore, follow all the install again while inside your coppafish environment.</p> <p>You can verify your install by running <code>pip show coppafish</code> in the coppafish environment to check you have the  latest version.</p>"},{"location":"advanced_usage/","title":"Advanced Usage","text":""},{"location":"advanced_usage/#email-notification","title":"Email notification","text":"<p>To be emailed when the pipeline crashes or finishes, under <code>basic_info</code> in the config, add the variable <code>email_me</code>  with your email address. You must have a sender email with SMTP support, this email's credentials must be given in  <code>basic_info</code> under the variables <code>sender_email</code> and <code>sender_email_password</code>.</p>"},{"location":"advanced_usage/#generate-gene-codes","title":"Generate gene codes","text":"<p>Generate gene codes automatically by:</p> <pre><code>from coppafish.utils import reed_solomon_codes\n\ncodes = reed_solomon_codes(n_gene_codes, n_rounds, n_channels)\n</code></pre> <p>where <code>n_gene_codes</code> is the number of gene codes desired, <code>n_rounds</code> is the number of sequencing rounds, and  <code>n_channels</code> is the number of channels. An error is thrown if the number of unique gene codes desired is impossible to  create. Each channel is labelled 0, 1, 2, ... <code>codes</code> is a dictionary. Each gene code generated can be accessed. For  example, to access the first gene code: <code>codes[\"gene_0\"]</code>.</p>"},{"location":"advanced_usage/#move-the-output-directory","title":"Move the output directory","text":"<p>Once a coppafish pipeline is complete or partially complete, the output directory will contain various files. If you  wish to move the output directory somewhere else while the notebook already exists, manually copy files to the new  output directory (including the notebook). Then use the following command:</p> <pre><code>from coppafish.utils import set_notebook_output_dir\n\nset_notebook_output_dir(\"path/to/new/notebook.npz\", \"new/output_dir\")\n</code></pre> <p>Note that this will not update the notebook when the tile directory is moved (see here). If  the notebook does not exist, it is safe to copy the output directory manually without running the command above.</p>"},{"location":"advanced_usage/#move-the-tile-directory","title":"Move the tile directory","text":"<p>The extracted and filtered images can also be moved to a new tile directory. First, manually move the tile directory to  a new location. Then, update the notebook to use the new tile directory by running the command:</p> <pre><code>from coppafish.utils import set_notebook_tile_dir\n\nset_notebook_tile_dir(\"path/to/notebook.npz\", \"path/to/new/tile_dir\")\n</code></pre> <p>This will only apply the new tile directory to the given notebook. You can run the function multiple times to update  every notebook you may have. If no notebook used the old tile directory, you can safely move the directory manually  without running the command above.</p>"},{"location":"advanced_usage/#retrieve-the-notebook-config","title":"Retrieve the Notebook config","text":"<p>Notebook's store a path to the config file, this can be accessed by doing</p> <pre><code>from coppafish import Notebook\n\nnb = Notebook(\"path/to/notebook\")\nconfig = nb.config_path\n</code></pre>"},{"location":"advanced_usage/#remove-notebook-page","title":"Remove notebook page","text":"<p>Each coppafish section is saved as a separate notebook page. To change the config variables and re-run the coppafish  pipeline, you can delete the notebook and all output directory files and re-run again. But, if you only wished to  re-run starting from an intermediate section, you can delete all subsequent sections and output files. For example, if  you wished to re-run OMP after changing OMP config parameters, you can delete the subdirectory called \"omp\" found  within the notebook directory.</p> <p>Now coppafish can be re-run and it will continue from OMP. This is particularly useful for many tile datasets. If you  are unsure what must be re-run, then it is suggested to start from an empty output directory.</p>"},{"location":"advanced_usage/#skipping-bad-microscope-images","title":"Skipping bad microscope images","text":"<p>You may have one or more images that are taken which are corrupted, empty, or not as bright as expected. When this happens, the user can manually tell coppafish to run without these images. To do this, specify each tile (<code>t</code>), round (<code>r</code>), channel (<code>c</code>) image by going to your custom config file and add the line</p> <pre><code>bad_trc = (t1, r1, c1), (t2, r2, c2), ...\n</code></pre> <p>under the <code>basic_info</code> section. Each set of brackets represents one image to ignore.</p>"},{"location":"basic_usage/","title":"Basic Usage","text":""},{"location":"basic_usage/#input-data","title":"Input data","text":"<p>Coppafish requires raw, <code>uint16</code> microscope images, metadata, and a configuration file. We currently only support raw  data in ND2, JOBs, or numpy format. If your data is not already in one of these formats, we recommend configuring your  data into numpy format.</p>"},{"location":"basic_usage/#nd2","title":"ND2","text":"<p>ND2 files index tiles differently to coppafish. The difference is illustrated below on a 2x3 grid.</p> How six tiles are indexed."},{"location":"basic_usage/#numpy","title":"Numpy","text":"<p>Each round is separated between directories. Label sequencing round directories <code>0</code>, <code>1</code>, etc. We recommend using  dask, this is installed in your coppafish environment by default. The code to save data in the  right format would look something like</p> <pre><code>import os\nimport dask.array\n\nraw_path = \"/path/to/raw/data\"\ndask_chunks = (1, n_total_channels, n_y, n_x, n_z)\nfor r in range(n_seq_rounds):\n    save_path = os.path.join(raw_path, f\"{r}\")\n    image_dask = dask.array.from_array(seq_image_tiles[r], chunks=dask_chunks)\n    dask.array.to_npy_stack(save_path, image_dask)\n\n# Anchor round\nsave_path = os.path.join(raw_path, \"anchor\")\nimage_dask = dask.array.from_array(anchor_image, chunks=dask_chunks)\ndask.array.to_npy_stack(save_path, image_dask)\n</code></pre> <p>where <code>n_...</code> variables represent counts (integers), <code>n_total_channels</code> can include other channels other than the  sequencing channel (e.g. a DAPI channel and anchor channel). <code>seq_image_tiles</code> is a numpy array of shape  <code>(n_seq_rounds, n_tiles, n_total_channels, n_y, n_x, n_z)</code>, while <code>anchor_image</code> is a numpy array of shape  <code>(n_tiles, n_total_channels, n_y, n_x, n_z)</code>. Note that <code>n_y</code> must equal <code>n_x</code>.</p>"},{"location":"basic_usage/#metadata","title":"Metadata","text":"<p>The metadata can be saved using python:</p> <pre><code>import json\n\nmetadata = {\n    \"n_tiles\": n_tiles,\n    \"n_rounds\": n_rounds,\n    \"n_channels\": n_total_channels,\n    \"tile_sz\": n_y, # or n_x\n    \"pixel_size_xy\": 0.26,\n    \"pixel_size_z\": 0.9,\n    \"tile_centre\": [n_y / 2, n_x / 2, n_z / 2],\n    \"tilepos_yx\": tile_origins_yx,\n    \"tilepos_yx_nd2\": list(reversed(tile_origins_yx)),\n    \"channel_camera\": [1] * n_total_channels,\n    \"channel_laser\": [1] * n_total_channels,\n    \"xy_pos\": tile_xy_pos,\n    \"nz\": n_z,\n}\nfile_path = os.path.join(raw_path, \"metadata.json\")\nwith open(file_path, \"w\") as f:\n    json.dump(metadata, f, indent=4)\n</code></pre>"},{"location":"basic_usage/#code-book","title":"Code book","text":"<p>A code book is a <code>.txt</code> file that tells coppafish the expected gene codes for each gene. An example of a four  gene code book is <pre><code>gene_0 0123012\ngene_1 1230123\ngene_2 2301230\ngene_3 3012301\n</code></pre> the names (<code>gene_0</code>, <code>gene_1</code>, ...) can be changed. Do not assign any genes a constant gene code, e.g. <code>0000000</code>. To  learn how the codes can be generated, see advanced usage. For details on how the codes are  generated, see <code>reed_solomon_codes</code> in  <code>coppafish/utils/base.py</code>. See the   Wikipedia article for how gene codes are best selected.</p>"},{"location":"basic_usage/#configuration","title":"Configuration","text":"<p>There are configuration variables used throughout the coppafish pipeline. Most of these have reasonable default values,  but some must be set by the user and you may wish to tweak other values for better performance. Save the config file as  something like <code>config.ini</code>. The config file should contain, at the minimum: <pre><code>[file_names]\ninput_dir = path/to/input/data\noutput_dir = path/to/output/directory\ntile_dir = path/to/tile/output\nround = 0, 1, 2, 3, 4, 5, 6 ; Go up to the number of sequencing rounds used\nanchor = anchor\nraw_extension = .npy\nraw_metadata = path/to/metadata.json\n\n[basic_info]\nis_3d = True\ndye_names = dye_0, dye_1, dye_2, dye_3\nuse_rounds = 0, 1, 2, 3, 4, 5, 6\nuse_z = 0, 1, 2, 3, 4\nuse_tiles = 0, 1\nanchor_round = 7\nuse_channels = 1, 2, 3, 4\nanchor_channel = 1\ndapi_channel = 0\n\n[stitch]\nexpected_overlap = 0.15\n</code></pre> where the <code>dapi_channel</code> is the index in the numpy arrays that the dapi channel is stored at. <code>use_channels</code> includes  the <code>anchor_channel</code> in this case because the anchor channel can also be used as a sequencing channel in the sequencing  rounds. <code>dye_names</code> does not have to be set explicitly if <code>n_seq_channels == n_dyes</code>. <code>expected_overlap</code> is the  fraction of the tile in x (y) dimension that is overlapping between adjacent tiles, typically <code>0.1-0.15</code>. More details  about every config variable can be found at   <code>coppafish/setup/settings.default.ini</code> in the source code. <code>use_z</code> contains all selected z planes, they should all  be adjacent planes. It is recommended to use microscopic images where the middle z plane is roughly the brightest for  best performance; this can be configured by changing the selected z planes in <code>use_z</code>. The z direction can be treated  differently to the y and x directions because typically a z pixel corresponds to a larger, real distance.</p>"},{"location":"basic_usage/#running","title":"Running","text":"<p>Coppafish can be run with a config file. In the terminal <pre><code>python -m coppafish /path/to/config.ini\n</code></pre></p> <p>Or using a python script <pre><code>from coppafish import run_pipeline\n\nrun_pipeline(\"/path/to/config.ini\")\n</code></pre></p>"},{"location":"call_spots/","title":"Call Spots","text":"<p>The Call Reference Spots section of the pipeline is a method of gene calling which runs quickly on a small set of spots (\\(\\approx\\) 50, 000 per tile) of the anchor image. Initially, this was our final mode of gene calling, but has since been superseded by OMP, which differs from Call Spots in that it runs on several more pixels, regardless of whether they have been detected as a spot.</p> <p>Despite this, the call spots section is still a crucial part of the pipeline as it estimates several important parameters used in the OMP section.</p> <p>Some of the most important exported parameters of this section are:</p> <ul> <li> <p>Colour Normalisation Factor \\(\\mathbf{A}\\):  \\((n_{\\text{t}} \\times n_{\\text{r}} \\times n_{\\text{c}})\\) array which multiplies the colours to minimise any systematic brightness variability between different tiles, rounds and channels and maximise spectral separation of dyes,</p> </li> <li> <p>Bleed Matrix \\(\\mathbf{B}\\): \\((n_{\\text{d}} \\times n_{\\text{c}})\\) array of the typical channel spectrum of each dye.</p> </li> <li> <p>Bled Codes \\(\\mathbf{K}\\): \\((n_{\\text{g}} \\times n_{\\text{r}} \\times n_{\\text{c}})\\) array of the expected colour spectrum for each gene.</p> </li> </ul>"},{"location":"call_spots/#algorithm-breakdown","title":"Algorithm Breakdown","text":"Algorithm Flowchart showing how all variables and steps of the pipeline are related. <p>The inputs to the algorithm are:</p> <ul> <li> <p>Raw spot colours \\(F_{src}\\) for all spots \\(s\\) (defined as local maxima of round \\(r_{\\text{anchor}}\\), channel \\(c_{\\text{anchor}}\\)) and the tile \\(t(s)\\) they belong to.</p> </li> <li> <p>A list of genes \\(g\\) and their associated dye codes \\(d(g, r)\\) for each round \\(r\\). These codes were generated by the Reed-Solomon Algorithm which should minimise the number of overlap between codes.</p> </li> <li> <p>A raw bleed matrix \\(\\mathbf{B_{\\textrm{raw}}}\\) of shape \\((n_{\\text{dyes}} \\times n_{\\text{c}})\\) obtained from images of free-floating drops of each dye.</p> </li> </ul>"},{"location":"call_spots/#0-preprocessing","title":"0: Preprocessing","text":"<p>The purpose of this step is to approximately equalise the brightness of different tiles, rounds and channels and to remove any background which is constant across rounds from each spot.</p> <p>We transform the raw spot colours \\(F_{src}\\) as follows:</p> \\[F_{src} \\mapsto \\tilde{A}_{t(s)rc}F_{src} - G_{sc}.\\] <p>In the formula above:</p> <ul> <li>The initial normalisation factor \\(\\tilde{A}_{trc}\\) is defined as</li> </ul> \\[ \\tilde{A}_{trc} = \\dfrac{1}{\\text{Percentile}_s(F_{src}, 95)} \\] <p>for all spots \\(s\\) in tile \\(t\\). This is a good estimate of the scaling factor needed to make the brightest spots in each tile, round and channel have the same intensity.</p> <ul> <li>The ground level \\(G_{sc}\\) is defined as</li> </ul> \\[ G_{sc} = \\text{Percentile}_r(\\tilde{A}_{t(s)rc}F_{src}, 25). \\] <p>For 7 rounds, this is the brightness of the second dimmest round of the scaled spot colours in channel \\(c\\). This is a good estimate of the constant signal in channel \\(c\\) across all rounds, which we want to remove.</p>"},{"location":"call_spots/#1-initial-gene-assignment","title":"1: Initial Gene Assignment","text":"<p>The purpose of this step is to provide some preliminary gene assignments that will allow us to estimate the bleed matrix and the bled codes. We will work extensively with the bleed matrix in these calculations, but bear in mind that this is the raw bleed matrix \\(\\mathbf{B_{\\textrm{raw}}}\\).</p> <p>We'd like to define a probability that spot \\(s\\) (fluorescence \\(F_{src}\\)) comes from gene \\(g\\), and we'd like this probability to have the following properties:</p> <ol> <li> <p>The probability of round \\(r\\) being assigned to dye \\(d\\) should be invariant to changes in the overall brightness of \\(\\mathbf{F_{sr}}\\),</p> </li> <li> <p>the probabilities of each round \\(r\\) should be independent.</p> </li> </ol> Why these properties? <p>Property 1 is desirable because of the way the bridge probes work in the experiment, as shown below. </p> <p><p>  The 3 probe system. </p></p> <p>Upon every mRNA transcript of interest, several padlock-probes are attached. These stay fixed in place throughout the experiment. To illuminate each gene with the expected dye in each round, bridge probes (which are gene-specific on one arm and dye-specific on the other) are transported to all the padlock probes associated with this spot and ligated.</p> <p>The brightness of each gene in each round is proportional to the amount of bridge probes that have ligated. Unfortunately, the number of bridge probes varies wildly between genes and rounds, giving rise to systematic differences in brightness between genes and rounds. </p> <p>Normalising the brightnesses of each spot in each round is a way to get around this problem.</p> <p><p>  Spots assigned to the gene Chrm 1 had many more bridge probes in round 4 than round 3, leading to systematic brightness differences. </p></p> <p>Property 2 is only approximately true, but independence between rounds makes the formula for the probability of a spot being assigned to a gene much simpler.</p> <p>Let:</p> <ul> <li> <p>\\(\\mathbf{f} = (\\mathbf{f_1}, \\ldots, \\mathbf{f_{n_r}}) ^ T\\) be the \\((n_r \\times n_c)\\) round-normalised fluorescence matrix of the spot,</p> </li> <li> <p>\\(\\mathbf{b}_g = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\) be the \\((n_r \\times n_c)\\) round-normalised bled code for gene \\(g\\).</p> </li> </ul> <p>We define the probability of spot \\(s\\) being assigned to gene \\(g\\) as</p> \\[ \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}] = \\frac{\\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})}{\\sum_{g'} \\exp(\\kappa\\mathbf{b}_{g'} \\cdot \\mathbf{f})},\\] <p>where \\(\\kappa\\) is a concentration parameter which controls how much the probabilities are spread out among the genes.</p> <p>How to choose \\(\\kappa\\)?</p> <p>The parameter \\(\\kappa\\) is set by adjusting the config parameter <code>kappa</code> and has default value 2. The value of \\(\\kappa\\) controls how much the probabilities are spread out among the genes, but does not influence the gene ordering.</p> <ul> <li> <p>\\(\\kappa = 0\\) yields a uniform distribution of probabilities between all genes,</p> </li> <li> <p>\\(\\kappa \\rightarrow \\infty\\) yields a distribution that tends to 1 for the gene with the maximum dot product and 0 for all others.</p> </li> </ul> <p><p>  Effects of varying \\(\\kappa\\) on the probabilities of a single spot. </p></p> <p>When working with larger gene panels, all probabilities are spread out more naturally, so it helps to increase \\(\\kappa\\) so that probabilities have a consistent interpretation. Out current implementation sets \\(\\kappa = 2\\) if \\(n_g &lt; 200\\) and 3 otherwise.</p> Gene Probability Derivation"},{"location":"call_spots/#dye-probabilities","title":"Dye Probabilities","text":"<p>We'll model the normalised round fluorescence vectors \\(\\mathbf{F_r}\\) arising from dye \\(d\\) as being random and distributed according to a von Mises-Fisher distribution with mean \\(\\mathbf{B_d}\\) and concentration parameter \\(\\kappa\\).</p> <p>This model has probability density function</p> \\[\\mathbb{P}[\\mathbf{F_{r}} = \\mathbf{f_r} \\mid D = d] =  M_{\\kappa} \\exp(\\kappa\\mathbf{f_r} \\cdot \\mathbf{B_d}),\\] <p>where \\(\\mathbf{f_r}\\) is a unit vector and \\(M_{\\kappa}\\) is a normalization constant we don\u2019t need to worry about.</p>"},{"location":"call_spots/#gene-probabilities","title":"Gene Probabilities","text":"<p>Now let \\(\\mathbf{F} = (\\mathbf{F_1}, \\ldots, \\mathbf{F_{n_r}}) ^ T\\) be the \\((n_r \\times n_c)\\) matrix of normalised fluorescence vectors of each round \\(r\\) of a spot \\(s\\). By independence between rounds, the probability of observing the fluorescence \\(\\mathbf{f}\\) from a spot of gene \\(g\\) is just the product of the probabilities that each round \\(r\\) is assigned to dye \\(d(g, r)\\). In equations, this simplifies nicely to:</p> \\[  \\begin{aligned} \\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] &amp;= \\prod_r \\mathbb{P}[\\mathbf{F_{r}} = \\mathbf{f_r} \\mid D = d(g, r)] \\\\  &amp;= \\prod_r M_{\\kappa} \\exp \\left( \\kappa\\mathbf{f_r} \\cdot \\mathbf{B_{d(g, r)}} \\right) \\\\ &amp;= M_{\\kappa}^{n_r} \\exp \\left( \\kappa \\sum_r \\mathbf{f_r} \\cdot \\mathbf{B_{d(g, r)}} \\right) \\\\  &amp;=  M_{\\kappa}^{n_r} \\exp(\\kappa \\mathbf{f \\cdot b_g}), \\end{aligned} \\] <p>where</p> <ul> <li> <p>\\(\\mathbf{f} = (\\mathbf{f_1}, \\ldots, \\mathbf{f_{n_r}}) ^ T\\) is the observed round-normalised \\((n_r \\times n_c)\\) fluorescence matrix of the spot,</p> </li> <li> <p>\\(\\mathbf{b_g} = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\) is the \\((n_r \\times n_c)\\) matrix of the bled code for gene \\(g\\),</p> </li> <li> <p>the dot product \\(\\mathbf{f \\cdot b_g}\\) is the Frobenius Inner Product for Matrices, ie: the sum of the elementwise product of the two matrices.</p> </li> </ul> <p>We have so far only defined the probability of \\(\\mathbf{F} = \\mathbf{f}\\) given \\(G = g\\). We can find the probability of \\(G = g\\) given \\(\\mathbf{F} = \\mathbf{f}\\) using Bayes' Rule:</p> \\[  \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}]  = \\dfrac{\\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] \\mathbb{P}[G = g]}{ \\mathbb{P}[\\mathbf{F} = \\mathbf{f}]}.  \\] <p>For the priors, we will assume that:</p> <ul> <li> <p>\\(\\mathbb{P}[G = g] = \\frac{1}{n_g}\\) (ie: all genes are equally likely),</p> </li> <li> <p>\\(\\mathbb{P}[\\mathbf{F} = \\mathbf{f}] = \\sum_g \\mathbb{P}[\\mathbf{F} = \\mathbf{f} \\mid G = g] \\mathbb{P}[G = g] = \\frac{1}{n_g} \\sum_g M_{\\kappa}^{n_r} \\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})\\), (ie: \\(\\mathbf{f}\\) comes from one of the genes)</p> </li> </ul> <p>This gives us the final probability:</p> \\[ \\mathbb{P}[G = g \\mid \\mathbf{F} = \\mathbf{f}] = \\frac{\\exp(\\kappa \\mathbf{b}_g \\cdot \\mathbf{f})}{\\sum_g \\exp(\\kappa\\mathbf{b}_g \\cdot \\mathbf{f} )}\\]"},{"location":"call_spots/#2-bleed-matrix-calculation","title":"2: Bleed Matrix Calculation","text":"<p>The purpose of this step is to compute an updated estimate of the bleed matrix. </p> <p>Set some probability threshold \\(\\gamma\\) (in the config file \\(\\gamma\\) is called <code>gene_prob_thresold</code> and has default value 0.9). We define the following sets:</p> \\[  \\mathcal{S} = \\{ s : p(s) \\geq \\gamma \\}, \\] \\[  G_{rd} = \\{ g : d(g,r) = d \\}, \\] \\[  J_{rd} = \\{ \\mathbf{F_{sr}} \\in \\mathbb{R}^{n_c}: s \\in \\mathcal{S}, \\ g_s \\in G_{rd} \\} \\] <p>In words, these can be described as follows:</p> <ul> <li> <p>\\(\\mathcal{S}\\) is the set of spots with \\(s\\) with probability \\(p(s) &gt; \\gamma\\), ie: the high probability spots,</p> </li> <li> <p>\\(G_{rd}\\) is the set of genes with dye \\(d\\) in round \\(r\\),</p> </li> <li> <p>\\(J_{rd}\\) is the set of colours of high probability spots assigned to genes with dye \\(d\\) in round \\(r\\).</p> </li> </ul> <p>By taking the union of \\(J_{rd}\\) across rounds, we end up with a set of reliable colour vector estimates for dye \\(d\\):</p> \\[  \\mathcal{J}_d = \\bigcup_r J_{rd} \\] Why do we find spots like this? <p>The simpler way to find represantitive colours for each dye would be to look at the colours for all spots \\(s\\) where \\(\\mathbf{F_{sr}} \\cdot \\mathbf{B_{raw, d}}\\) is above some threshold. This would give us a set of colours which are likely to be from dye \\(d\\). </p> <p>Our method is better for two reasons:</p> <ol> <li>The raw bleed matrix \\(\\mathbf{B_{raw}}\\) is not always good estimate of the bleed matrix.</li> <li>The central dyes have very similar colour spectra, so it is difficult to classify which dye the vector comes from by looking at round \\(r\\) alone. By using information from adjacent rounds, we can more confidently ensure that the colours we are looking at are from dye \\(d\\).</li> </ol> <p>Let \\(\\mathbf{J}\\) be the \\((n_{\\text{good spots}} \\times n_c)\\) matrix form of the set \\(\\mathcal{J}_d\\). This just means each row of \\(\\mathbf{J}\\) corresponds to a good spot and each column corresponds to a channel. Compute the first singular vectors of \\(\\mathbf{J}\\), ie: the optimal unit vectors \\(\\boldsymbol{\\omega} \\in \\mathbb{R}^{n_c}\\) and \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^{n_{\\text{good spots}}}\\) such that</p> \\[ J_{s, c} \\approx \\lambda \\eta_s \\omega_c, \\] <p>for some scalar \\(\\lambda\\). We then set \\(\\mathbf{B_d} = \\boldsymbol{\\omega}\\), which is a normalised fluorescence vector for dye \\(d.\\)</p>"},{"location":"call_spots/#3-free-bled-code-estimation","title":"3: Free Bled Code Estimation","text":"<p>The purpose of this step is to estimate a representative colour, which we call a free bled code \\(E_{grc}\\) for each gene \\(g\\). </p> <p>What makes these codes free?</p> <p>\\(E_{grc}\\) is free in the sense that for each gene \\(g\\), \\(E_{grc}\\) is only determined by spots assigned to gene \\(g\\) and not by spots assigned to other genes.</p> <p>Our method of estimating the tile-independent free bled codes \\(\\mathbf{E_{g}}\\) (and similarly the tile-dependent free bled codes \\(\\mathbf{D_{g,t}}\\)) should satisfy the following properties:</p> <ul> <li> <p>If we have no spots, we should use a prior vector \\(\\mathbf{E_g} = (\\mathbf{B_{d(g, 1)}}, \\ldots, \\mathbf{B_{d(g, n_r)}}) ^ T\\),</p> </li> <li> <p>We should allow each round \\(\\mathbf{E_{gr}}\\) to scale \\(\\mathbf{B_{d(g, r)}}\\) easily,</p> </li> <li> <p>We should allow each round \\(\\mathbf{E_{gr}}\\) to change the direction of \\(\\mathbf{B_{d(g, r)}}\\) less easily, but still allow it to change.</p> </li> </ul> Why these properties? <ul> <li> <p>Property 1 is necessary because for large gene panels we often have very few reads of each gene, meaning that we have very few samples to compute \\(\\mathbf{E_g}\\) and even fewer to compute \\(\\mathbf{D_{g, t}}\\).</p> </li> <li> <p>Property 2 is necessary because, as mentioned previously, different concentrations of bridge probes lead to systematic differences in brightness between genes in different rounds. We want to allow the brightness of each gene in each round to be scaled up or down without needing very many samples to do so.</p> </li> <li> <p>Property 3 is necessary because sometimes the way that a particular dye is expressed varies from gene to gene. An example of this is when the dyes are not completely washed out between rounds, leading to a small amount of bleedthrough from the previous round. </p> </li> </ul> <p>In the example below, both CPLX2 and FOS have dye 2 in their codes (R5 and R4 respectively), but due to incomplete washout of dye 0 in R3 of CPLX2 these genes have very different codes for dye 2.</p> CPLX2FOS <p><p>  Bleedthrough into R5, Dye 2. </p></p> <p><p>  No bleedthrough into R6, D2. </p></p> <p>The following mean satisfies all the properties mentioned above. Given \\(n\\) round fluorescence vectors \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n}\\) and a prior unit vector \\(\\mathbf{b}\\), all in \\(\\mathbb{R}^{n_c}\\), we define the parallel bayes mean of these as </p> \\[ \\mathbf{\\bar{F}}_{\\alpha\\beta}(\\mathbf{b}) = \\dfrac{\\alpha^2}{n + \\alpha^2} \\mathbf{b} + \\dfrac{1}{n + \\alpha^2} \\bigg( \\sum_i \\mathbf{f_i \\cdot b} \\bigg) \\mathbf{b} +  \\dfrac{1}{n+\\beta^2} \\sum_i \\bigg( \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b} \\bigg). \\] <p>The values \\(\\alpha^2\\) and \\(\\beta^2\\) are in the config file as <code>concentration_parameter_parallel</code> (default value 10) and <code>concentration_parameter_perpendicular</code> (default value 50) respectively.</p> How to choose and interpret \\(\\alpha\\) and \\(\\beta\\)? <p>The formula for \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) is quite complcated, but it is actually quite easy to interpret once we understand what it is doing for different values of \\(\\alpha\\) and \\(\\beta\\).</p> <ul> <li> <p>If \\(\\alpha = \\beta = 0\\), this is just the average. ie: \\(\\mathbf{\\bar{F}}_{0,0}(\\mathbf{b}) = \\frac{1}{n} \\sum_i \\mathbf{f_i}\\),</p> </li> <li> <p>if \\(\\alpha = \\beta = m\\), for some positive integer \\(m\\), this is the average of \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n}\\) and \\(m\\) copies of \\(\\mathbf{b}\\), ie: $\\(\\mathbf{\\bar{F}}_{m,m}(\\mathbf{b}) = \\frac{1}{n + m} \\sum_i \\mathbf{f_i} + \\frac{m}{n + m} \\mathbf{b}\\).</p> </li> <li> <p>From the previous point, we see that if \\(\\alpha = \\beta = \\infty\\), this is just the prior vector \\(\\mathbf{b}\\), ie: \\(\\mathbf{\\bar{F}}_{\\infty, \\infty}(\\mathbf{b}) = \\mathbf{b}\\).</p> </li> <li> <p>The component of \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) parallel to \\(\\mathbf{b}\\) has magnitude \\(\\frac{\\alpha^2 + \\sum_i \\mathbf{f_i} \\cdot \\mathbf{b}}{n + \\alpha^2}\\), which means that:</p> <ul> <li> <p>If \\(n &lt;&lt; \\alpha^2\\) this magnitude is approximately 1, so this component is approximately \\(\\mathbf{b}\\),</p> </li> <li> <p>If \\(n &gt;&gt; \\alpha^2\\) this magnitude is approximately \\(\\frac{1}{n} \\sum_i (\\mathbf{f_i} \\cdot \\mathbf{b} ) \\mathbf{b}\\), which is the magnitude of the sample mean \\(\\mathbf{\\bar{f}}\\) in the direction \\(\\mathbf{b}\\).</p> </li> </ul> </li> <li> <p>The component of \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) perpendicular to \\(\\mathbf{b}\\) has magnitude \\(\\frac{1}{n + \\beta^2} \\sum_i ( \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b} )\\) which means that:</p> <ul> <li> <p>If \\(n &lt;&lt; \\beta^2\\) this magnitude is approximately 0, so this component is approximately \\(\\mathbf{0}\\),</p> </li> <li> <p>If \\(n &gt;&gt; \\beta^2\\) this magnitude is approximately \\(\\frac{1}{n} \\sum_i \\mathbf{f_i} - (\\mathbf{f_i} \\cdot \\mathbf{b})\\mathbf{b}\\), which is the sample mean \\(\\mathbf{\\bar{f}}\\) perpendicular to \\(\\mathbf{b}\\).</p> </li> </ul> </li> </ul> <p>From this analysis, we see that \\(\\alpha^2\\) is roughly the number of spots needed to scale \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) in the direction of \\(\\mathbf{b}\\), and \\(\\beta^2\\) is roughly the number of spots needed to scale \\(\\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{b})\\) perpendicular to \\(\\mathbf{b}\\). </p> <p>This is why we to set \\(\\alpha^2 &lt;&lt; \\beta^2\\). We want to easily scale the average in the direction of the prior vector, but not easily change its direction.</p> <p>We use these to estimate the free bled codes \\(\\mathbf{E_{gr}}\\) for each gene \\(g\\) and round \\(r\\) as follows:</p> <p>Let \\(\\mathbf{f_1}, \\ldots, \\mathbf{f_n} \\in \\mathbb{R}^{n_c}\\) be the round \\(r\\) fluorescence vectors of spots assigned to gene \\(g\\) with probability greater than \\(\\gamma\\) and let \\(\\mathbf{B_{d(g, r)}}\\) be the prior unit vector. We then set each round \\(r\\) to have free bled codes \\(\\mathbf{E_{gr}}\\) given by</p> \\[ \\mathbf{E_{gr}} = \\mathbf{\\bar{F}}_{\\alpha \\beta}(\\mathbf{B_{d(g, r)}}). \\] <p>The case for \\(\\mathbf{D_{g, t}}\\) is exactly analogous, except we use the fluorescence vectors of spots assigned to gene \\(g\\) in tile \\(t\\) with probability greater than \\(\\gamma\\).</p> Derivation of the Parallel Bayes Mean <p>The formula for the parallel bayes mean is a maximum a posteriori estimate. This means that we view the data as coming from a particular distribution with some unkown mean \\(\\boldsymbol{\\mu}\\), which we want to estimate. We have some prior beliefs about what \\(\\boldsymbol{\\mu}\\) should be and how this should vary, which we encode in a prior distribution of potential values for \\(\\boldsymbol{\\mu}\\). The observed data has a certain probability given \\(\\boldsymbol{\\mu}\\), and by Bayes rule each \\(\\boldsymbol{\\mu}\\) has a probability given the data. The maximum a posteriori estimate \\(\\boldsymbol{\\hat{\\mu}}\\) is the value of \\(\\boldsymbol{\\mu}\\) which maximises this conditional probability distribution.</p> <p>Let \\(\\mathbf{F_1}, \\ldots, \\mathbf{F_n}\\)  be the round \\(r\\) fluorescence vectors of spots assigned to gene \\(g\\) with high probability and let \\(\\mathbf{B}_{d(g,r)}\\) be the prior unit vector.</p> <p>To begin, assume the vectors \\(\\mathbf{F_1}, \\ldots, \\mathbf{F_n}\\) are i.i.d normal random variables with mean \\(\\boldsymbol{\\mu}\\) and covariance \\(I_{n_c}\\), wihch means the sample mean is also normal with mean \\(\\boldsymbol{\\mu}\\) and covariance \\(\\frac{I_{n_c}}{n}\\). Impose a normal prior on the space of possible means:</p> \\[ \\overline{\\mathbf{F}} \\sim \\mathcal{N} \\bigg( \\boldsymbol{\\mu}, \\frac{\\boldsymbol{I_{n_c}}}{n} \\bigg) \\] \\[ \\boldsymbol{\\mu} \\sim \\mathcal{N}(\\mathbf{B}_{d(g,r)}, \\Sigma) \\] <p>where </p> \\[ \\Sigma = \\text{Diag}\\left(\\frac{1}{\\alpha^2}, \\frac{1}{\\beta^2}, \\ldots, \\frac{1}{\\beta^2}\\right), \\] <p>in the orthonormal basis \\(\\mathbf{v}_1 = \\mathbf{B}_{d(g,r)}\\), and everything else orthogonal to this.</p> <p>Set \\(\\boldsymbol{\\Lambda} =\\boldsymbol{\\Sigma}^{-1}\\), \\(\\mathbf{b} = \\mathbf{B_{d(g,r)}}\\), and recall that the normal is a conjugate prior, meaning the posterior \\(\\boldsymbol{\\mu} \\mid \\mathbf{\\overline{F}}\\) is also normal. </p> <p>To find its mode we'll solve for the zeros of the derivative of its log-density. The log-density of \\(\\boldsymbol{\\mu} \\mid \\mathbf{\\overline{F}}\\) is given by</p> \\[ \\begin{aligned} l(\\boldsymbol{\\mu}) &amp;= \\log P(\\boldsymbol{\\mu}| \\overline{\\mathbf{F}} = \\mathbf{f}) \\\\ \\\\        &amp;= \\log P(\\boldsymbol{\\mu}) + \\log P(\\overline{\\mathbf{F}} = \\mathbf{f} | \\boldsymbol{\\mu}) + C \\\\ \\\\        &amp;= -\\frac{1}{2} (\\boldsymbol{\\mu} - \\mathbf{b})^T \\boldsymbol{\\Lambda} (\\boldsymbol{\\mu} - \\mathbf{b}) - \\frac{n}{2} (\\boldsymbol{\\mu} - \\mathbf{f})^T (\\boldsymbol{\\mu} - \\mathbf{f}) + C \\end{aligned} \\] <p>This has derivative</p> \\[ \\frac{\\partial l}{\\partial \\boldsymbol{\\mu}} = - \\boldsymbol{\\Lambda} (\\boldsymbol{\\mu} - \\boldsymbol{b}) - n(\\boldsymbol{\\mu} - \\mathbf{f}) \\] <p>Setting this to \\(\\mathbf{0}\\), rearranging for \\(\\boldsymbol{\\mu}\\) and using the fact that</p> \\[ \\boldsymbol{\\Lambda} \\mathbf{v} =  \\begin{cases} \\alpha^2 \\mathbf{v} &amp; \\text{if } \\mathbf{v} = \\lambda\\mathbf{b} \\\\ \\\\ \\beta^2 \\mathbf{v} &amp; \\text{otherwise} \\end{cases} \\] <p>we get</p> \\[ \\begin{aligned} \\boldsymbol{\\hat{\\mu}} &amp;= (\\Lambda + nI)^{-1}(\\Lambda \\mathbf{b} + n\\mathbf{f}) \\\\ \\\\      &amp;= (\\Lambda + nI)^{-1}(\\alpha^2 \\mathbf{b} + n\\mathbf{f}) \\\\ \\\\     &amp;= (\\Lambda + nI)^{-1}(\\alpha^2 \\mathbf{b} + n(\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} + n(\\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b})) \\\\ \\\\     &amp;= (\\Lambda + nI)^{-1}((\\alpha^2 + n \\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} + n(\\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b}))\\\\ \\\\ &amp;= \\dfrac{(\\alpha^2 + n \\mathbf{f} \\cdot \\mathbf{b})}{n + \\alpha^2} \\mathbf{b} +  \\dfrac{n}{n+\\beta^2} \\bigg( \\mathbf{f} - (\\mathbf{f} \\cdot \\mathbf{b})\\mathbf{b} \\bigg) \\end{aligned} \\] <p>Plugging in the observed sample mean \\(\\mathbf{f} = \\frac{1}{n}\\sum_i \\mathbf{f_{i, r}}\\) yields our estimate \\(\\boldsymbol{\\hat{\\mu}}\\).</p>"},{"location":"call_spots/#4-round-and-channel-normalisation","title":"4: Round and Channel Normalisation","text":"<p>The purpose of this step is to find a scale factor \\(V_{rc}\\) for each round \\(r\\) and channel \\(c\\) which gets as many of our spots as close as possible to their target values. We will then multiply \\(V_{rc}\\) by the free bled codes \\(E_{grc}\\) to get the constrained bled codes \\(K_{grc}\\). </p> <p>What makes these codes constrained?</p> <p>The codes \\(K_{grc}\\) are constrained in the sense that the value of \\(K_{grc}\\) is determined by several genes other than \\(g\\).</p> <p>These codes have nice global properties, like as many genes as possible being as close as possible to their target values, but will not be representative of the spots assigned to gene \\(g\\). This is addressed in section 5, where we will be to find a scale to get the spots as close as possible to these new constrained bled codes.</p> <p>The target values work as follows: </p> <ul> <li> <p>\\(T\\) is defined as <code>target_values</code> in the config file as a list of length \\(n_c\\). </p> </li> <li> <p>\\(T_c\\) is the target value for channel \\(c\\) in its representative dye \\(d_{\\textrm{max}}(c)\\),</p> </li> <li> <p>\\(d_{\\textrm{max}}\\) is defined as <code>d_max</code> in the config file as a list of length \\(n_c\\). </p> </li> <li> <p>\\(d_{\\textrm{max}}(c)\\) is the dye we use to represent channel \\(c\\), and we want to get its brightness in channel \\(c\\), \\(B_{d_{\\textrm{max}}(c), c}\\) as close as possible to \\(T_c\\).</p> </li> </ul> <p>Any gene that has dye \\(d_{\\textrm{max}}(c)\\) in round \\(r\\) will have its free bled code \\(E_{grc}\\) scaled by \\(V_{rc}\\) to get as close as possible to \\(T_c\\). Since \\(E_{grc}\\) is a representative colour for all spots assigned to gene \\(g\\), this will also get the spots as close as possible to their target values. </p> <p>As in section 2 above, let \\(G_{rd}\\) be the set of genes with dye \\(d\\) in round \\(r\\) and define the loss function </p> \\[ L(V_{rc}) = \\sum_{g \\in G_{r, \\ d_{max}(c)}} \\sqrt{N_{g}} \\  \\bigg( V_{rc} \\ E_{grc} - T_{c} \\bigg)^2, \\] <p>where \\(N_g\\) is the number of high probability spots assigned to gene \\(g\\). There is no reason this has to be a square root, though if it is not, too much influence is given to the most frequent genes. We minimise this loss to obtain the optimal value</p> \\[ V_{rc} = \\dfrac{ \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_g} E_{grc} T_{c} } { \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_g} E_{grc}^2 }, \\] <p>Now define the constrained bled codes, which we will just call bled codes </p> \\[ K_{grc} = E_{grc}V_{rc}. \\]"},{"location":"call_spots/#5-tile-normalisation","title":"5: Tile Normalisation","text":"<p>The purpose of this step is to remove brightness differences between images from different tiles in the same round and channel. We do this by finding a scale factor \\(Q_{trc}\\) for each tile \\(t\\), round \\(r\\) and channel \\(c\\) which gets as many of our spots on tile \\(t\\) as close as possible to \\(K_{grc}\\).</p> <p>Our method works almost identically to step 4. Let \\(G_{rd}\\) be the genes with dye \\(d\\) in round \\(r\\). Define the loss</p> \\[ L(Q_{trc}) = \\sum_{g \\in G_{r, \\ d_{max}(c)}} \\sqrt{N_{g,t}} \\  \\bigg( Q_{trc} \\ D_{gtrc} - K_{grc} \\bigg)^2, \\] <p>where \\(N_{g, t}\\) is the number of high probability spots of gene \\(g\\) in tile \\(t\\). </p> If Q is correcting for tile differences, why does it have indices for \\(r\\) and \\(c\\)? <p>The scale factor \\(Q_{trc}\\) is defined to correct for differences in brightness between tiles, but the way that the brightness varies between tiles is completely independent for different round-channel pairs. </p> <p>This is because the cause of brightness differences between tiles is largely random from image to image, as can be observed by looking at spots in the overlapping regions of adjacent tiles in the same round and channel.</p> <p>We minimise this loss to obtain the optimal value</p> \\[ Q_{trc} = \\dfrac{ \\sum_{g \\in G_{r, \\ d_{max}(c) }} \\sqrt{N_{gt}} \\ K_{grc}  D_{gtrc}} { \\sum_{g \\in G_{r,\\ d_{max}(c) }} \\sqrt{N_{gt}}  D_{gtrc}^2 }. \\]"},{"location":"call_spots/#6-and-7-application-of-scales-computation-of-final-scores-and-bleed-matrix","title":"6 and 7: Application of Scales, Computation of Final Scores and Bleed Matrix","text":"<p>All that is left to do is multiply the spot colours \\(F_{src}\\) by the updated normalisation factor \\(Q_{trc}\\) to get the final spot colours: \\(F_{src} \\mapsto Q_{trc} F_{src}\\).</p> <p>We then compute the cosine similarity between each spot colour \\(\\mathbf{F_s}\\) and each bled code \\(\\mathbf{K_{grc}}\\) to get the two variables</p> <ul> <li><code>dot_product_gene_no[s]</code> = \\(\\textrm{argmax}_g \\bigg( \\dfrac{\\mathbf{F_s \\cdot K_{g}}}{\\| \\mathbf{F_s} \\| \\| \\mathbf{K_{g}} \\|} \\bigg)\\),</li> <li><code>dot_product_gene_score[s]</code> = \\(\\textrm{max}_g \\bigg( \\dfrac{\\mathbf{F_s \\cdot K_{g}}}{\\| \\mathbf{F_s} \\| \\| \\mathbf{K_{g}} \\|} \\bigg)\\).</li> </ul> <p>We also compute probabilities for each spot \\(s\\) being assigned to gene \\(g\\) as</p> <ul> <li><code>gene_prob[s, g]</code> = \\(\\dfrac{\\exp(\\kappa \\mathbf{K_{g} \\cdot F_s})}{\\sum_{g'} \\exp(\\kappa \\mathbf{K_{g'} \\cdot F_s})}\\),</li> </ul> <p>where \\(\\mathbf{F_s}\\) and \\(\\mathbf{K_{g}}\\) have both been round-normalised. Finally, with these updated gene assignments, we can compute the final bleed matrix \\(\\mathbf{B}\\) in the same way as in step 2.</p>"},{"location":"call_spots/#diagnostics","title":"Diagnostics","text":"<p>Diagnosing the quality of the gene assignments is a crucial part of the pipeline. We provide several diagnostics to help with this:</p>"},{"location":"call_spots/#view-scaling-and-bg-removal","title":"View Scaling And BG Removal","text":"<p><pre><code>from coppafish.plot.call_spots import ViewScalingAndBGRemoval\nViewScalingAndBGRemoval(nb)\n</code></pre> (or simply press 'N' in the main results' viewer)</p> <p>  Viewing the background removal and scaling of a subset of isolated spots. </p> <p>This shows a subset of 10,000 isolated spots in descending order of amount of background. The images on the top row are spot colours, each flattened into a single row and demarcated into channels by the red vertical lines. The plots on the bottom row show the intensity of a bright spot in each round channel.</p> <p>This plot shows us a few things:</p> <ul> <li> <p>Certain channels have much higher background than others. The final column is a good check that the background has been removed.</p> </li> <li> <p>Different channels have different baseline brightnesses. Check that the brightnesses in the middle and final column are to your liking and similar to the target values.</p> </li> <li> <p>The final brightnesses are not all the same: this is because we imposed channel-specific target values in step 4. This is a good check that the target scaling is working as expected.</p> </li> </ul>"},{"location":"call_spots/#view-bleed-matrix","title":"View Bleed Matrix","text":"<pre><code>from coppafish.plot.call_spots import ViewBleedMatrix\nViewBleedMatrix(nb)\n</code></pre> <p>(or simply press 'B' in the main results' viewer)</p> <p>  Viewing the bleed matrix. </p> <p>This viewer shows 3 bleed matrices, each with columns (dyes) normalised.</p> <ul> <li> <p>The first is the raw bleed matrix \\(\\mathbf{B_{raw}}\\) which is the initial estimate of the bleed matrix, used for the very first gene assignments in step 1.</p> </li> <li> <p>The second is the initial bleed matrix \\(\\tilde{\\mathbf{B}}\\) made from an SVD of high probability spots. This is scaled according to the initial scale factor \\(\\tilde{A}_{trc}\\) introduced in step 0. This is why channel 10 is so much brighter than its target value.</p> </li> <li> <p>The final bleed matrix \\(\\mathbf{B}\\) is the bleed matrix estimated from the final gene assignments, on high probability spots. This is scaled according to the final scale factor \\(A_{trc} = Q_{trc}\\tilde{A}_{trc}\\). You should be able to see the values are roughly in the same ratios as the target values.</p> </li> </ul>"},{"location":"call_spots/#view-free-and-constrained-bled-codes","title":"View Free And Constrained Bled Codes","text":"<pre><code>from coppafish.plot.call_spots import ViewFreeAndConstrainedBledCodes\nViewFreeAndConstrainedBledCodes(nb)\n</code></pre> <p>This will pull up a viewer that shows you the free bled codes \\(E_{grc}\\) and the constrained bled codes \\(K_{grc}\\) from the most influential genes for a given round and channel. This is a good way to check if the target scale \\(V_{rc}\\) is working as expected.</p> <p>To view different rounds and channels, simply scroll.</p> R0C5R2C15 <p><p> <p></p> <p><p> <p></p> <p>If this works as expected, the constrained bled codes should have values close to their target values and the constrained bled codes should be more homogeneous than the free bled codes. This can be seen in the first image, where R0C5 is initially very bright, but after scaling is much closer to the brightnesses of the other rounds and channels.</p>"},{"location":"call_spots/#view-target-regression","title":"View Target Regression","text":"<pre><code>from coppafish.plot.call_spots import ViewTargetRegression\nViewTargetRegression(nb)\n</code></pre> <p>This viewer is similar to the previous one in that it is showing how well the target scaling is working. It does this in a bit more detail, but is a little confusing!</p> <p>To view different rounds and channels, simply scroll.</p> R0C27R4C5 <p><p> <p></p> <p><p> <p></p> <p>In the plots above:</p> <ul> <li>Each dot is a gene, which has dyed \\(d_{\\textrm{max}}(c)\\) in round \\(r\\).</li> <li>The size of the dot is proportional to the number of spots assigned to that gene.</li> <li>The x-axis values are completely random.</li> <li>In the leftmost column, the y-axis values are the brightnesses \\(E_{grc}\\) of the genes after the initial scaling \\(\\tilde{A}_{trc}\\) but before the target scaling \\(V_{trc}\\).</li> <li>In the middle column, the y-axis values are the brightnesses \\(K_{grc}\\) of the genes after the target scaling \\(V_{trc}\\).</li> </ul> <p>It is important to check how well each round and channel is being scaled to its target value. R0C27 is pretty good, with most of the genes being pretty concentrated at the target value. R4C5 is much noisier, with many genes consistently too bright or too dim.</p>"},{"location":"call_spots/#view-tile-scale-regression","title":"View Tile Scale Regression","text":"<p><pre><code>from coppafish.plot.call_spots import ViewTileScaleRegression\nViewTileScaleRegression(nb, t)\n</code></pre> This function looks at a fixed tile and then shows the regression for the tile scale factor \\(Q_{trc}\\) for each round and channel. Recall that this is the scale factor that multiplies the tile-dependent free bled codes \\(D_{gtrc}\\) to get the constrained bled codes \\(K_{grc}\\).</p> <p>As in the previous diagnostic, each spot is a gene with dye \\(d_{\\textrm{max}}(c)\\) in round \\(r\\) and the size of the dot is proportional to the number of spots assigned to that gene. Unlike the previous diagnostic, in this plot the x-values are not random, but are the brightnesses \\(D_{gtrc}\\) of the genes (averaged from spots which have been multiplied by initial scale \\(\\tilde{A}_{trc}\\)). The y-values are the brightnesses \\(K_{grc}\\). </p> <p>A couple of things to note:</p> <ul> <li> <p>Different slopes within the same column (channel) indicate that this is picking up on differences in round brightnesses for this channel on this tile.</p> </li> <li> <p>If these regressions have a low \\(R^2\\) value, the tile scaling is not working well. This may be a sign of a blank tile or poor registration.</p> </li> </ul> <p>  Viewing the background removal and scaling of a subset of isolated spots. <p>  ### View Scale Factors  <pre><code>from coppafish.plot.call_spots import ViewScaleFactors\nViewScaleFactors(nb)\n</code></pre>  This simple viewer shows the target scale $V_{rc}$, the tile scale $Q_{trc}$ and the relative scale $Q_{trc}/V_{rc}$ for each round and channel.   What to expect:  - The tile scale $Q_{trc}$ should be close to $V_{rc}$ for each tile $t$. This is because $D_{gtrc}Q_{trc} \\approx K_{grc = E_{grc}V_{rc}}$. So if $E_{grc} \\approx D_{gtrc}$, then $Q_{trc} \\approx V_{rc}$.  - The relative scale measures how much we deviate from the vase where $E_{grc} = D_{gtrc}$, and should not have a huge amount of variance. In the plot above the highest value is 0.5 and the lowest is 0.35, which is a good range.  <p> <p>  ### Gene Efficiency Viewer <pre><code>from coppafish.plot.call_spots import GeneEfficiencyViewer\nGeneEfficiencyViewer(nb, score_threshold=gamma, mode=gene_assignment_mode)\n</code></pre>  (or simply press 'E' in the main results' viewer)  <p> <p>  Each row represents a gene and each column a round. The colour of each cell is the amount of weight that gene $g$ has in round $r$. The ideal case would be homogeneous colours across the rows, indicating that each gene is equally bright in each round, but this is never the case.  Look out for:  - Genes with an abnormal amount of spots assigned to them. This is often the case for poor quality genes which look a lot like background. If this is the case, the gene probability threshod `gene_prob_thresh` in the config file should be increased.  - Genes with very high or low gene efficiencies. This should not happen if `concentration_parameter_parallel` is sufficiently high, as it typically should need at least 10 spots to scale each dye. If the gene efficiencies are incorrect, OMP will struggle to find the correct gene assignments.  ### Gene Spots Viewer <pre><code>from coppafish.plot.call_spots import GeneSpotsViewer\nGeneSpotsViewer(nb, score_threshold=gamma, gene_index=g, mode=gene_assignment_mode)\n</code></pre>  (or simply click one of the genes in the gene efficiency viewer)  <p> <p>  This viewer shows the spots assigned to a particular gene above a certain threshold, under a certain gene assignment mode (either 'anchor', 'prob' or 'omp').   This is the viewer I use the most. It helps me find abnormalities that would be hard to spot otherwise, like the persistent unexpected channel 27 signal in round 0 in the images above. If a particular gene is under or over expressed, this viewer will typically tell us why. It also gives us a very nice representation of which dyes, rounds and channels are clean and which are noisy."},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#the-algorithm","title":"The Algorithm","text":"<p>Coppafish is built on the basis that an algorithm that performs well does not need to be changed. The algorithm is only  updated when there is evidence that it can perform better and that the current algorithm is performing worse.</p>"},{"location":"contributing/#our-philosophy","title":"Our Philosophy","text":"<p>We follow some basic rules when coding. Anyone can code something that works, but coding it in a scaleable,  maintainable way is another struggle altogether.</p> <p>Here are some specific standards to follow:</p> <ul> <li>Knowledge written down twice is bad code. Don't Repeat Yourself (DRY)!</li> <li>If a bug is found, the bug must be automatically found if it is to occur again.</li> <li>Every time a function is modified or created, a new unit test must be created for the function. A pre-existing unit  test can be drawn from to build a new unit test, but it should be clear in your mind that you are affectively building  a new function.</li> <li>Minimise <code>if</code>/<code>else</code> branching as much as possible. Exit <code>if</code>/<code>else</code> nesting as  soon as possible through the use of keywords like <code>continue</code>, <code>break</code> and <code>return</code> whenever feasible.</li> <li>Every docstring for a function must be complete so a developer can re-create the function without seeing any of the  existing source code.</li> <li>Each parameter in a function must have an independent, clear functionality. If two parameters are derivable from  one another, you are doing something wrong.</li> <li>Minimise the number of data types a parameter can be and use common sense. For example, a parameter that can be  <code>int</code> or <code>None</code> is reasonable. A parameter that can be <code>bool</code> or <code>float</code> is not  reasonable.</li> <li>The documentation should update in parallel with the code. Having the documentation as part of the github repository  is done to make this as easy as possible. </li> <li>Do not over-shorten a variable or function name.</li> <li>In most cases, a line of code should do only one operation.</li> </ul>"},{"location":"diagnostics/","title":"Diagnostics","text":""},{"location":"diagnostics/#viewer","title":"Viewer","text":"<p>The Viewer is coppafish's flagship way of viewing final results. It is a fast, three-dimensional view of gene reads  found by coppafish using napari.</p>"},{"location":"diagnostics/#opening","title":"Opening","text":"<p>A Viewer can be displayed once coppafish has run through at least call spots. Do this by</p> <pre><code>from coppafish import Notebook, Viewer\nnb = Notebook(\"path/to/notebook.npz\")\nViewer(nb)\n</code></pre> <p>where a new napari tab will be opened. You can specify a how genes are marked using a .csv file, then the Viewer can be  opened by</p> <pre><code>from coppafish import Notebook, Viewer\nnb = Notebook(\"path/to/notebook.npz\")\nViewer(nb, gene_marker_file=\"path/to/custom/gene_marker_file.csv\")\n</code></pre> <p>see  here for the default .csv file for gene markers.</p>"},{"location":"diagnostics/#description","title":"Description","text":"<p>The greyscale signal in the background is the DAPI (if no DAPI is included in the dataset, then the anchor image is  displayed instead); whiter regions indicate cells. Each gene is given a unique shape and colour, shown in the gene  legend. A gene can be toggled by left clicking on it in the gene legend, right click a gene to show only that type.</p> <p>For help with Viewer hotkeys, press Shift + k. This includes further diagnostic plots built into the Viewer.</p> <p>The \"Image Contrast\" slider below the gene legend will affect the colour scale of the DAPI image. The \"z Thickness\"  allows for multiple z planes of genes to be displayed at once. Genes further away in z are smaller. The \"Score Range\"  allows the user to change the minimum and maximum scores to be displayed. The \"Intensity Threshold\" affects the minimum  allowed spot intensity to display (only affects Anchor and OMP). The \"Method\" is the chosen method of gene calling.  \"Prob\" is the Von-Mises probability method, \"Anchor\" is the anchor method (see call spots), and  \"OMP\" is the Orthogonal Matching Pursuit method (see OMP). The \"OMP Score  Multiplier\" will affect how much weight positive coefficient has over negative coefficient parts of a spot. We  recommend a value \\(\\ge1\\), but there is no known optimal value.</p> <p></p>"},{"location":"diagnostics/#registrationviewer","title":"RegistrationViewer","text":""},{"location":"diagnostics/#opening_1","title":"Opening","text":"<pre><code>from coppafish import RegistrationViewer, Notebook\n\nnb = Notebook(\"path/to/notebook.npz\")\nRegistrationViewer(nb, t=t)\n</code></pre> <p>where <code>t</code> is a tile index you want to view registration results for. If <code>t</code> is set to <code>None</code> (default), then the lowest  tile index is displayed.</p>"},{"location":"diagnostics/#pdf-diagnostics","title":"PDF Diagnostics","text":"<p>During a pipeline run, multiple .pdf files are created for different sections. These are located in the output  directory. They can be manually created from the notebook file by <pre><code>from coppafish import BuildPDF\n\nBuildPDF(\"path/to/notebook.npz\")\n</code></pre></p> <p>specify the directory to save to by <pre><code>BuildPDF(\"path/to/notebook.npz\", \"path/to/output/directory\")\n</code></pre> if you want the PDFs to be re-created, you must delete the old ones first.</p>"},{"location":"diagnostics/#viewer2d","title":"Viewer2D","text":"<p>To open <pre><code>from coppafish import Notebook, Viewer2D\n\nnb = Notebook(\"path/to/notebook.npz\")\nViewer2D(nb)\n</code></pre></p> <p>The viewer is updated by typing commands in the terminal. To find out the available commands, type <code>help</code> or <code>h</code>.</p>"},{"location":"diagnostics/#viewing-images","title":"Viewing images","text":""},{"location":"diagnostics/#raw-images","title":"Raw images","text":"<p>Raw images for particular tiles, round, and channels can be viewed with access to <code>nb.file_names.input_dir</code>:</p> <pre><code>from coppafish import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook.npz\")\nplot.view_raw(nb, tiles, rounds, channels)\n</code></pre> <p>where <code>tiles</code>, <code>rounds</code>, and <code>channels</code> are lists of integers specifying which images to view.</p>"},{"location":"diagnostics/#extracted-images","title":"Extracted images","text":"<p>Extracted images are identical to raw images, these are viewed by</p> <pre><code>from coppafish import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook.npz\")\nplot.view_extracted_images(nb, tiles, rounds, channels)\n</code></pre> <p>where <code>tiles</code>, <code>rounds</code>, and <code>channels</code> are lists of integers specifying which images to view. Set these to <code>None</code> if  you wish to view all of the them from the sequencing images.</p>"},{"location":"diagnostics/#filtered-images","title":"Filtered images","text":"<p>Images after all filtering are viewed by</p> <pre><code>from coppafish import Notebook, plot\n\nnb = Notebook(\"/path/to/notebook.npz\")\nplot.view_filtered_images(nb, tiles, rounds, channels)\n</code></pre> <p>where <code>tiles</code>, <code>rounds</code>, and <code>channels</code> are lists of integers specifying which images to view. Set these to <code>None</code> if  you wish to view all of the them from the sequencing images.</p>"},{"location":"glossary/","title":"Glossary","text":"<ul> <li> <p>Anchor round - A one-time round taken, usually on a chosen \"anchor channel\" that has a high Signal-to-Noise Ratio  (SNR). All genes of interest are given the same fluorescing dye probe. The anchor round is essential for detecting all  spots at once in the same microscope image.</p> </li> <li> <p>Channel - A combination of excitation light of a certain wavelength and specific emission filter. We use multiple  channels to distinguish every dye colour (almost always the number of channels is equal to the number of unique dyes).  But, a dye can have \"bleed through\", i.e. brightness in multiple channels from the same dye.</p> </li> <li> <p>DAPI - A dye that fluoresces the nuclei of all cells. It is used to register the round images to one another. The  DAPI is also an overlay in the Viewer.</p> </li> <li> <p>Gene code - A sequence of dyes that are assigned to a gene for each sequencing round. Each gene has a unique gene  code. For example, if the dyes are labelled <code>0, 1, 2</code> and there are 2 sequencing rounds, some example gene codes are  <code>0, 1</code> (i.e. dye <code>0</code> in first round, dye <code>1</code> in second round), <code>1, 2</code>, <code>0, 2</code>.</p> </li> <li> <p>Notebook - A write-once<sup>1</sup> compressed file that stores all important outputs from coppafish. The notebook is used  to plot many diagnostics. The notebook contains notebook pages. There is a notebook page for each  method section. A notebook can be loaded by  <code>from coppafish import Notebook; nb = Notebook(\"path/to/notebook.npz\")</code>. Variables from the notebook can be directly  read. For example, you can read the <code>use_tiles</code> variable from the <code>basic_info</code> page by  <code>print(nb.basic_info.use_tiles)</code>. Each variable also has a description, which can be printed. For example,  <code>nb.basic_info.describe(\"use_tiles\")</code>.</p> </li> <li> <p>OMP - Stands for Orthogonal Matching Pursuit. It is the final section of the coppafish pipeline. It is coppafish's  most sophisticated algorithm for gene calling and is used as a way of untangling genes that overlap on images by  assuming that the pixel intensity is a linear combination of each gene intensity. There is no reason to believe that  gene intensity would combine non-linearly.</p> </li> <li> <p>Point cloud - A series of spatial pixel positions. Typically used to represent detected spot positions during  find spots.</p> </li> <li> <p>PSF - Stands for Point Spread Function and is used during image filtering. The Wiener deconvolution requires a PSF to  remove blurring caused by frequencies with a low signal-to-noise ratio. See the  Wikipedia article for more details.</p> </li> <li> <p>Sequencing round - An image of the tissue, made up of multiple tiles and sequencing channels. Before each imaging  round, the tissue is treated with various solutions to remove the previous DNA probes and then hybridise new ones. Each  spot will bind to a specific bridge probe and then fluorescing dye probe, causing it to fluoresce in specific  channel(s). The colour of each spot in each round is dictated by its gene identity (identities) and their corresponding  gene code(s). </p> </li> <li> <p>Spot - An amplified ball of DNA with a unique barcode specific to each gene. The gene can be determined by looking at  the same spot in all sequencing rounds to reveal the gene code. Coppafish takes the raw images of the spots as input  and outputs the identity of each gene in situ.</p> </li> <li> <p>Tile - A cuboid subset of the microscope image of size \\(n_z \\times n_y \\times n_x\\) in z, y, and x, where \\(n_y = n_x\\).  Typically, \\(n_z\\sim55\\). Usually, all adjacent tiles overlap by \\(10\\%-15\\%\\) to give coppafish information on how to best  align tiles (see stitch for details).</p> </li> </ul> <ol> <li> <p>There are some minor cases of a notebook being \"rewritten\", see advanced usage.\u00a0\u21a9</p> </li> </ol>"},{"location":"omp/","title":"Orthogonal Matching Pursuit (OMP)","text":"<p>OMP is coppafish's current best gene assignment algorithm. OMP runs independently, except requiring  register for image-alignment and call spots for dataset-accurate  representation of each gene's unique barcode: its bled code (\\(\\mathbf{B}_{grc}\\)). OMP does not explicitly differentiate  between sequencing rounds and channels.</p>"},{"location":"omp/#definitions","title":"Definitions","text":"<ul> <li>\\(r\\) and \\(c\\) represents sequencing rounds and channels respectively.</li> <li>\\(\\mathbf{B}_{grc}\\) represents gene g's bled code in round \\(r\\), channel \\(c\\).</li> <li>\\(\\mathbf{S}_{prc}\\) is pixel \\(p\\)'s colour in round \\(r\\), channel \\(c\\), after pre-processing is applied.</li> <li>\\(\\mathbf{c}_{pgi}\\) is the OMP coefficient given to gene \\(g\\) for image pixel \\(p\\) on the \\(i\\)'th iteration. \\(i\\) takes  values \\(1, 2, 3, ...\\)</li> <li>\\(||...||^{(...)}\\) represents an L2 norm (or Frobenius norm for a matrix) over indices within the brackets.</li> </ul>"},{"location":"omp/#0-pre-processing","title":"0: Pre-processing","text":"<p>All tile pixel colours are gathered using the results from register. Any out of bounds round/channel colour intensities  are set to zero. </p>"},{"location":"omp/#1-assigning-the-next-gene","title":"1: Assigning the Next Gene","text":"<p>A pixel can have more than one gene assigned to it. The most genes allowed on each pixel is <code>max_genes</code>  (typically <code>10</code>). Let's say we are on iteration \\(i\\) (\\(i = 1, 2, 3, ...\\)) for pixel \\(p\\). The pixel will already have  \\(i - 1\\) genes assigned to it and their coefficients have already been computed (\\(\\mathbf{c}_{pg(i - 1)}\\)). We compute  the latest residual pixel colour \\(\\mathbf{R}_{prci}\\) as </p> \\[ \\mathbf{R}_{prci} = \\mathbf{S}_{prc} - \\sum_g(\\mathbf{c}_{pg(i - 1)}\\mathbf{B}_{grc}) \\] <p>For the first iteration, \\(\\mathbf{R}_{prc(i=1)} = \\mathbf{S}_{prc}\\). Using this residual, a dot product score is  computed for every gene and background gene \\(g\\) as </p> \\[ (\\text{gene scores})_{pgi} = \\frac{\\sum_{rc}(\\mathbf{B}_{grc}\\mathbf{R}_{prci})}{||\\mathbf{R}_{prci}||^{rc} + \\lambda_d} \\] <p>A gene is successfully assigned to a pixel when all conditions are met:</p> <ul> <li>The best gene score is above <code>dp_thresh</code> (typically 0.225).</li> <li>The best gene is not already assigned to the pixel.</li> <li>The best gene is not a background gene.</li> <li>There are fewer than \\(\\text{max_genes} - i + 1\\) genes/background genes above the <code>dp_thresh</code> score.</li> </ul> <p>The reasons for each of these conditions is:</p> <ul> <li>to remove poor gene reads and dim pixels.</li> <li>to not double assign genes.</li> <li>to avoid over-fitting on high-background pixel colour.</li> <li>to stop iterating on ambiguous pixel colour.</li> </ul> <p>respectively. If a pixel fails to meet one or more of these conditions, then no more genes are assigned to it. If all  remaining pixels fail the conditions, then the iterations stop and the coefficients \\(\\mathbf{c}\\) are kept as final.</p>"},{"location":"omp/#2-gene-coefficients","title":"2: Gene Coefficients","text":"<p>On each iteration, the gene coefficients are computed for the genes assigned to pixel \\(p\\) to best represent the  pixel's colour. All unassigned genes have a zero coefficient, so \\(g\\) here represents only the assigned genes (\\(i\\)  assigned genes). The coefficients vector, \\(\\mathbf{c}_{pgi}\\), is of length \\(g\\). \\(\\mathbf{c}_{pgi}\\) is computed through  the method of least squares by minimising the scalar residual </p> \\[ \\sum_{rc}(\\mathbf{S}_{prc} - \\sum_{g}(\\mathbf{B}_{grc}\\mathbf{c}_{pgi}))^2 \\] <p>In other words, using matrix multiplication, the coefficient vector of length genes assigned is </p> \\[ \\mathbf{c} = \\bar{\\mathbf{B}}^{-1} \\bar{\\mathbf{S}} \\] <p>where \\(\\bar{(...)}\\) represents flattening the round and channel dimensions into a single dimension, so  \\(\\bar{\\mathbf{B}}\\) is of shape \\(\\text{genes assigned}\\) by \\(\\text{rounds}*\\text{channels}\\) and \\(\\bar{\\mathbf{S}}\\) is of  shape \\(\\text{rounds} * \\text{channels}\\). \\((...)^{-1}\\) is the Moore-Penrose matrix inverse (a pseudo-inverse).</p> <p>With the new, updated coefficients, step 1 is repeated on the remaining pixels unless \\(i\\) is equal to <code>max_genes</code>.</p>"},{"location":"omp/#3-coefficient-post-processing","title":"3: Coefficient Post-Processing","text":"<p>The final coefficients, \\(\\mathbf{c}_{pg}\\) are normalised pixel-wise by</p> \\[ \\mathbf{c}_{pg} \\rightarrow \\frac{\\mathbf{c}_{pg}}{||\\mathbf{S}_{prc}||^{rc} + \\lambda_d} \\] <p>\\(\\lambda_d\\) should be on the order of background signal, typically \\(0.4\\).</p>"},{"location":"omp/#4-mean-sign-spot-computation","title":"4: Mean Sign Spot Computation","text":""},{"location":"overview/","title":"Overview","text":"<p>The coppafish pipeline is separated into distinct sections. Some of these are for image pre-processing (extract, filter), image alignment (register, stitch) and spot  detection/gene calling (find spots, call spots,  orthogonal matching pursuit). Below, each section is given in the order a coppafish pipeline runs in.</p>"},{"location":"overview/#extract","title":"Extract","text":"<p>Save all raw data again at the <code>tile_dir</code> in the <code>extract</code> config section. Coppafish does this for:</p> <ul> <li>file compression.</li> <li>saving raw data in a consistent format.</li> <li>faster data retrieval. The default file type is using zarr arrays, but coppafish also supports saving as uncompressed numpy arrays by setting <code>file_type</code> to <code>.npy</code> in the extract config section.</li> </ul> <p>Extract also saves metadata inside of the <code>tile_dir</code> directory if the raw files are ND2 format.</p>"},{"location":"overview/#filter","title":"Filter","text":"<p>All images are filtered to help minimise scattering of light (bright points will appear as cones initially, hence the name \"Point Spread Function\") and emphasise spots. A given point spread function is used to Wiener deconvolve the  images.</p> <p>After filtering is applied, the images are scaled by a computed scale factor and then saved in <code>uint16</code> format again.</p>"},{"location":"overview/#find-spots","title":"Find spots","text":"<p>Point clouds (a series of spot x, y, and z locations) are generated for each filtered image. These are found by detecting local maxima in image intensity around the rough spot size (specified by config variables <code>radius_xy</code> and <code>radius_z</code> in the <code>find_spots</code> section). If two local maxima are the same value and in the same spot region, then one is chosen at random. Warnings and errors are raised if there are too few spots detected in a round/channel, these can be customised, see <code>find_spots</code> section in the  config default file for variable names.</p>"},{"location":"overview/#register","title":"Register","text":""},{"location":"overview/#stitch","title":"Stitch","text":""},{"location":"overview/#call-spots","title":"Call spots","text":""},{"location":"overview/#orthogonal-matching-pursuit","title":"Orthogonal Matching Pursuit","text":"<p>Orthogonal Matching Pursuit (OMP) is the most sophisticated gene calling method used by coppafish, allowing for overlapping genes to be detected. It is an iterative, greedy algorithm that runs on individual pixels of the images. At each OMP iteration, a new gene is assigned to the pixel. OMP is also self-correcting. \"Orthogonal\" refers to how OMP will re-compute its gene contributions after every iteration by least squares. Background genes<sup>1</sup> are considered valid genes in OMP. The iterations stop if:</p> <ul> <li><code>max_genes</code> in the <code>omp</code> config section is reached.</li> <li>assigning the next best gene to the pixel does not have a dot product score above <code>dp_thresh</code> in the <code>omp</code> config. The dot product score is a dot product of the residual pixel intensity in every sequencing round/channel (known as its colour) with the normalised bled codes (see call spots).</li> </ul> <p>Sometimes, when a gene is chosen by OMP, a very strong residual pixel intensity can be produced when the selected gene is subtracted from the pixel colour. To protect against this, <code>weight_coef_fit</code> can be set to true and weighting parameter <code>alpha</code> (\\(\\alpha\\)) can be set in the <code>omp</code> config. When \\(\\alpha&gt;0\\), round/channel pixel intensities largely contributed to by previous genes are fitted with less importance in the next iteration(s). In other words, \\(\\alpha\\) will try soften any large outlier pixel intensities.</p> <p>After a pixel map of gene coefficients is found through OMP on many image pixels, spots are detected as local coefficient maxima (similar to find spots). Spots are scored by a weighted average around a small local region of the spot where the spot is expressed most strongly. The coefficients are weighted with the mean spot intensity normalised to have a maximum of 1. The mean spot is computed on tile <code>nb.basic_info.use_tiles[0]</code> by taking the average of many well-isolated spots. The scoring is controlled by config parameters <code>shape_sign_thresh</code>. Low scores  are deleted by OMP when they are below the <code>score_threshold</code>.</p> <p>Since OMP is sensitive to the many steps before, it can be difficult to optimise. This is why call spots is part of the gene calling pipeline, known for its simpler and more intuitive method. A good sanity check is to see if OMP and call spots have similar gene reads. But, you should expect to see more gene calls made by OMP compared to call spots.</p>"},{"location":"overview/#runtime","title":"Runtime","text":"<p>For an estimate of your pipeline runtime, in the Python terminal: <pre><code>from coppafish.utils import estimate_runtime\n\nestimate_runtime()\n</code></pre> then type in the relevant information when prompted<sup>2</sup>.</p> <ol> <li> <p>Background genes refer to constant pixel intensity across all sequencing rounds in one channel. This is an indicator of an anomalous fluorescing feature that is not a spot. No spot codes are made to be the same channel in all rounds so they are not mistaken with background fluorescence.\u00a0\u21a9</p> </li> <li> <p>All time estimations are made using an Intel i9-13900K @ 5.500GHz, NVIDIA RTX 4070Ti Super, and NVMe local SSD.  Raw, ND2 files were saved on a server with read speed of ~200MB/s.\u00a0\u21a9</p> </li> </ol>"},{"location":"register/","title":"Registration","text":"<p>The register section is the part of the pipeline concerned with aligning different rounds and channels. This is crucial for decoding spot colours into genes in the Call Spots and OMP sections. The aim of this section is to find a function \\(g_{trc}(\\mathbf{x})\\) for each tile, round and channel that takes in a location \\(\\mathbf{x}\\) on the anchor image for tile \\(t\\) and returns the corresponding location in round \\(r\\), channel \\(c\\) of the same tile. Since registration is done independently for each tile and we are often only working on one tile, we sometimes omit the subscript \\(t\\) in this documentation.</p> <p>Once we have these transformations \\(g\\), we can get a \\(n_{\\textrm{rounds}} \\times n_{\\textrm{channels}}\\) spot colours matrix \\(\\boldsymbol{F}(\\mathbf{x})\\) for each location \\(\\mathbf{x}\\) in the anchor image of a given tile via</p> \\[ \\boldsymbol{F}(\\mathbf{x}) = \\begin{pmatrix} f_{0, 0}(g_{0, 0}(\\mathbf{x})) &amp; \\cdots &amp; f_{0, n_c}(g_{0, n_c}(\\mathbf{x})) \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ f_{n_r, 0}(g_{n_r, 0}(\\mathbf{x})) &amp; \\cdots &amp; f_{n_r, n_c}(g_{n_r, n_c}(\\mathbf{x})) \\\\ \\end{pmatrix}, \\] <p>where \\(f_{rc}(\\mathbf{x})\\) is the intensity of round \\(r\\), channel \\(c\\) at location \\(\\mathbf{x}\\) in round \\(r\\), channel \\(c\\) coordinates. Note that even a single poorly aligned round or channel makes this matrix difficult to decode, which highlights the importance of this section.</p>"},{"location":"register/#high-level-overview","title":"High Level Overview","text":"<p>We need to consider a few questions when building the register pipeline. Some of the most important are:</p> <ol> <li> <p>How large should our search space of functions for \\(g\\) be? Are these functions independent between rounds and channels?</p> </li> <li> <p>How will we actually search this space?</p> </li> </ol>"},{"location":"register/#1-choosing-the-function-space","title":"1. Choosing the Function Space","text":"<p>To choose the set of functions we will use to fit to our data, we need to look for all sources of misalignment. Channel misalgnments are caused by:</p> <ul> <li> <p>The multiple camera setup, meaning channels belonging to different cameras are often slightly shifted or rotated with respect to one another.</p> </li> <li> <p>Chromatic aberration, the variable frequency-dependent dispersal of light through the lens. This expands the images from different channels by different amounts. See the figure below.</p> </li> </ul> <p>So the channel-to-channel differences are composed of shifts, rotations and scalings. We model each channel transform by an affine transform \\(A_c\\).</p> <p> An example of chromatic aberration. </p> <p>For round to round differences, we see much less predictable variability. Misalignments arise due to:</p> <ul> <li> <p>Tissue expansion in \\(z\\) throughout the rounds,</p> </li> <li> <p>Global shifts arising from movement of the stage,</p> </li> <li> <p>Variable local shifts due to the microfluidics system,</p> </li> <li> <p>Variable local shifts due to gravity or tissue deformation. These shifts have the potential to affect regions very differently. For example, the pyramidal layer is very densely packed and seems to sink more than surrounding areas, leading to different z-shifts in its vicinity. We have also observed rips within tissue samples, which cause different sides of the tissue to move in apart from each other in opposite directions.</p> </li> </ul> <p>The conclusion is that affine transformations do not sufficiently capture the richness of round-to-round transformations. We therefore allow for completely arbitrary transformations \\(\\mathcal{F}_r\\) for each round \\(r\\).</p> Affine Transform Failure Example <p>The figure below shows a rip in the tissue and the resulting misalignment in the DAPI channel. This is just one example of a misalignment that cannot be captured by an affine transform. <p> A rip in the tissue and two attempts at affine registration.  </p></p> <p>To answer the second part of question 1 - empirically, it seems we don't need to find \\(n_{\\textrm{rounds}} \\times n_{\\textrm{channels}}\\) independent transforms per tile, we only need \\(n_{\\textrm{rounds}} + n_{\\textrm{channels}}\\). Explicitly, we model every transform as </p> \\[  g_{rc}(\\mathbf{x}) = A_{c}(\\mathcal{F}_{r}(\\mathbf{x})). \\]"},{"location":"register/#2-computing-the-transforms","title":"2. Computing the Transforms","text":"<p>The round transforms are computed with Optical Flow, while the channel transforms are computed with Iterative Closest Point. For further details see the sections below.</p> Note on Affine Transforms <p>When we compute the round transforms \\(\\mathcal{F}_r\\) these often include some systematic error, like a small shift of 1 pixel and slight underestimation of the z-expansion. This is due to </p> <ul> <li> <p>downsampling of the images used to compute the optical flow transforms,</p> </li> <li> <p>A failure to find good shifts at z-boundaries, due to poor quality images in these planes.</p> </li> </ul> <p>To get around this, we find an affine correction \\(B_r\\) for each round. This means our functions \\(g_{rc}\\) can be written as </p> \\[ g_{rc}(\\mathbf{x}) = A_{c}(B_{r}(\\mathcal{F}_{r}(\\mathbf{x})). \\] <p>We combine the two affine transforms \\(A_c\\) and \\(B_r\\) to give us the simple formula </p> \\[ g_{rc}(\\mathbf{x}) = A_{rc}(\\mathcal{F}_{r}(\\mathbf{x})), \\] <p>which means that in practice our affine maps actually depend on round as well as channel.</p>"},{"location":"register/#optical-flow","title":"Optical Flow","text":"<p>We use optical flow to align the anchor DAPI \\(D_{r_{\\textrm{ref}}}(\\mathbf{x})\\)  to the round \\(r\\) DAPI \\(D_r(\\mathbf{x})\\). The output of this algorithm is a function \\(\\mathcal{F}_r\\) which satisfies the relation </p> \\[ D_{r_{\\textrm{ref}}}(\\mathcal{F}_r(\\mathbf{x})) = D_r(\\mathbf{x}). \\]"},{"location":"register/#1-how-does-it-work","title":"1. How does it work?","text":"<p>Suppose we have 2 images \\(I\\) and \\(J\\) which we'd like to register. This means for each position \\(\\mathbf{x}\\) in image \\(J\\) we would like to find the shift \\(\\mathbf{s}\\) satisfying </p> \\[ I(\\mathbf{x} + \\mathbf{s}) = J(\\mathbf{x}). \\] <p>Assuming that this \\(\\mathbf{s}\\) is small and that the function \\(I\\) is sufficiently smooth, we can approximate it by a linear function in this neighbourhood. Taylor expanding and rearranging yields:</p> \\[ \\mathbf{s} \\cdot \\boldsymbol{\\nabla} I(\\mathbf{x}) \\approx J(\\mathbf{x}) -  I(\\mathbf{x}), \\] <p>which is called the flow equation, an under-determined equation due to the fact that there are 3 unknowns - each component of \\(\\mathbf{s}\\). </p> <p>There are many different methods that exist to tackle this. The one we use is called the Lucas-Kanade method, which assumes that all pixels in a small window of radius \\(r\\) (the <code>window_radius</code> parameter with default value 8) around the point \\(\\mathbf{x}\\) have the same shift \\(\\mathbf{s}\\). </p> <p>Since this method assumes that all pixels have the same shift within this window, the condition that \\(I\\) is smooth is very important, as we need to ensure that the same flow equation holds for all \\(x\\) in the window. For this to be true, the Hessian \\(\\frac{\\partial ^2 I}{\\partial \\mathbf{x}^2}\\) cannot be too large in this window.</p> <p>Lucas-Kanade works as follows. Let \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) be all the points in this window. Then assuming these all have the same shift \\(\\mathbf{s}\\), we can gather the \\(n\\) flow equations</p> \\[ \\begin{pmatrix} \\boldsymbol{\\nabla} I(\\mathbf{x}_1)^T \\\\ \\vdots \\\\ \\boldsymbol{\\nabla} I(\\mathbf{x}_n)^T  \\end{pmatrix} \\mathbf{s} = \\begin{pmatrix} J(\\mathbf{x}_1) - I(\\mathbf{x}_1) \\\\ \\vdots \\\\ J(\\mathbf{x}_n) - I(\\mathbf{x}_n)  \\end{pmatrix},  \\] <p>which is now overdetermined! This is a better problem to have though, as the solution can be approximated by least squares.</p> <p>The above derivation makes the following assumptions</p> <ol> <li> <p>The shift \\(\\mathbf{s}\\) is small,</p> </li> <li> <p>The images are smooth. Ie, the Hessian \\(\\frac{\\partial ^2 I}{\\partial \\mathbf{x}^2}\\) is not too large,</p> </li> <li> <p>The images \\(I\\) and \\(J\\) have the same intensities, so that \\(I(\\mathbf{x} + \\mathbf{s}) = J(\\mathbf{x})\\).</p> </li> </ol> <p>To make sure we meet the assumptions we carry out the following steps:</p> <ol> <li> <p>Shift size:</p> <ul> <li> <p>We apply an initial Phase Correlation to find any global shift \\(\\mathbf{\\tilde{s}}\\) between \\(I\\) and \\(J\\), and shift \\(I\\) by this amount: \\(I(\\mathbf{x}) \\mapsto I(\\mathbf{x} - \\mathbf{\\tilde{s}})\\). Only once this is done do we carry out optical flow. This way, optical flow only captures the deviations from the global shift \\(\\mathbf{\\tilde{s}}\\).</p> </li> <li> <p>We downsample the images \\(I\\) and \\(J\\) in \\(y\\) and \\(x\\) before registration, which reduces the relative size of the shift.</p> </li> <li> <p>The implementation we use takes an iterative approach, meaning that after the initial flow field is found the algorithm runs again until some stopping criterion is met.</p> </li> </ul> </li> <li> <p>Smoothness:</p> <ul> <li>For practical reasons (speed and shift size), we need to downsample the images by a factor in \\(y\\) and \\(x\\) before registering. We perform the downsampling by taking the mean within each 4 by 4 sub-block as opposed to just extracting every 4th pixel in \\(y\\) and \\(x\\). This increases smoothness, as shown below.</li> <li>We smooth the images with a small Gaussian blur before registering. This needs to be done carefully because too much blurring decreases the resolution of the images and therefore the quality of the registration.</li> </ul> </li> <li> <p>To ensure we have similar intensity profiles we match the means of \\(I\\) and \\(J\\) in similar spatial locations.</p> </li> </ol> Smoothing Example <p>The figures below shows the effect of downsampling and blurring on the images. The Hessian determinants are shown on the right of the images.</p> Nearest Neighbour DownsamplingMean Sub-Block DownsamplingMean Sub-Block Downsampling + Gaussian <p><p> </p></p> <p><p> </p></p> <p><p> </p></p>"},{"location":"register/#2-practical-considerations","title":"2. Practical Considerations","text":""},{"location":"register/#speed","title":"Speed","text":"<p>Speed is an issue with this algorithm, because it needs to be run independently on so many pixels. We take the following steps to optimise it:</p> <ol> <li> <p>As mentioned above, we downsample the images in \\(y\\) and \\(x\\). The amount of donwsampling is controlled by the config parameter <code>sample_factor_yx</code> which has default value 4 in both directions, meaning that the algorithm runs 16 times faster than it would without downsampling.</p> </li> <li> <p>We split the downsampled images into 16 subvolumes (4 in \\(y\\) and 4 in \\(x\\)), and run optical flow in parallel on all of these independent subvolumes. The number of cores used can be adjusted by changing the <code>flow_cores</code> parameter though if left blank this will be computed automatically.</p> </li> </ol>"},{"location":"register/#interpolation","title":"Interpolation","text":"<p>As mentioned previously, the algorithm assumes that the images have the same intensities. This condition is certainly satisfied near cell nuclei, where similar features exist in both images. Far from nuclei though, where all we have is noise,  the 2 images have completely independent intensities. The result of this is that our flow fields tend to only give reliable results near nuclei, as shown below.</p> <p>  The shifts found by optical flow are only reliable in a small window around cell nuclei. </p> <p>This is problematic, as a lot of our reads are found in between cell nuclei! We need to interpolate the values in these regions. </p>"},{"location":"register/#hard-threshold-interpolation","title":"Hard Threshold Interpolation","text":"<p>Suppose we have a flow field \\(\\mathcal{F}\\) that we would like to interpolate. We might go about it in the following way:</p> <ol> <li> <p>Choose some locations \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) where we know the shifts computed \\(\\mathbf{s}_1, \\cdots, \\mathbf{s}_n\\) are reliable,</p> </li> <li> <p>Define the interpolated flow to be of the form </p> </li> </ol> \\[ \\mathcal{F}_{\\textrm{interp}}(\\mathbf{x}) = \\sum_i w(\\mathbf{x}, \\mathbf{x}_i) \\mathbf{s}_i , \\] <p>where the sum is over all sample points \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\), and the weights \\(w(\\mathbf{x}, \\mathbf{x}_i)\\) have the following properties:</p> <ul> <li> <p>\\(\\sum_i w(\\mathbf{x}, \\mathbf{x}_i) = 1\\) for all \\(\\mathbf{x},\\)</p> </li> <li> <p>\\(w(\\mathbf{x}, \\mathbf{x}_i)\\) is a decreasing function in \\(||\\mathbf{x}||\\) and \\(w(\\mathbf{x}_i, \\mathbf{x}_i) \\approx 1.\\)</p> </li> </ul> <p>If these 2 properties are met then \\(\\mathcal{F}_{\\textrm{interp}}\\) will be a weighted average of all the shifts \\(\\mathbf{s}_i\\), and since the weights are decreasing, the value of the \\(\\mathcal{F}_{\\textrm{interp}}\\) at each interpolation point \\(\\mathbf{x}_i\\) will be strongly weighted toward \\(\\mathbf{s}_i\\).</p> <p>Do such weight functions exist? Can we construct them? Yes and yes! Define the function </p> \\[ K(\\mathbf{x}, \\mathbf{y}) = \\exp \\Bigg( -\\frac{1}{2 \\sigma^2} ||\\mathbf{x} - \\mathbf{y}||^2 \\Bigg), \\] <p>then we can define the weights by</p> \\[  w(\\mathbf{x}, \\mathbf{x}_i) = \\dfrac{K(\\mathbf{x}, \\mathbf{x}_i)}{\\sum_j K(\\mathbf{x}, \\mathbf{x}_j)}. \\] <p>It is easy to see that this satisfies both the desired properties for the weights.</p> How to choose \\(\\sigma\\)? <p>In the limits: </p> <ul> <li> <p>as \\(\\sigma \\to 0\\) this tends to nearest neighbour interpolation, </p> </li> <li> <p>as \\(\\sigma \\to \\infty\\) the image takes the same value everywhere, the mean of the flow image at the sample points.</p> </li> </ul> <p>Another way of saying this is that as \\(\\sigma\\) grows, so does the radius of contributing pixels.</p> <p>We expect the shifts to vary more quickly in \\(z\\) than in \\(xy\\), so we have a different parameter for the blurring in each direction: <code>smooth_sigma</code>. This takes default values <code>[10, 10, 5]</code> (\\(y\\), \\(x\\) and \\(z\\)).</p>"},{"location":"register/#extension-to-soft-threshold-interpolation","title":"Extension to Soft Threshold Interpolation","text":"<p>The above method works well, but having a hard threshold means that some points \\(\\mathbf{x}_1, \\cdots, \\mathbf{x}_n\\) are used while others are completely ignored. This can lead to undersampling. A better approach is to employ a soft threshold, where we use all points \\(\\mathbf{x}_i\\) in the flow image but weight their contributions by the quality of the match at \\(\\mathbf{x}_i\\), which we will call \\(\\lambda(\\mathbf{x}_i)\\).</p> <p>This results in an interpolation of the form</p> \\[ \\mathcal{F}_{\\textrm{interp}}(\\mathbf{x}) = \\sum_i \\lambda(\\mathbf{x}_i) w(\\mathbf{x}, \\mathbf{x}_i) \\mathbf{s}_i , \\] <p>where the sum now ranges over all points in the image, and the weight functions are given by</p> \\[  w(\\mathbf{x}, \\mathbf{x}_i) = \\dfrac{K(\\mathbf{x}, \\mathbf{x}_i)}{\\sum_j \\lambda(\\mathbf{x}_j) K(\\mathbf{x}, \\mathbf{x}_j)}. \\] Definition of the Score \\(\\lambda\\) <p>Define the auxilliary score </p> \\[  \\eta(\\mathbf{x}) = D_{r_{\\textrm{ref}}}(\\mathcal{F}_r(\\mathbf{x}))D_r(\\mathbf{x}). \\] <p>Then our score \\(\\lambda\\) is defined as</p> \\[ \\lambda(\\mathbf{x}) = C_{0,1}\\bigg( \\dfrac{\\eta(\\mathbf{x}) - \\eta_0}{\\eta_1 - \\eta_0} \\bigg), \\] <p>where \\(\\eta_0\\) and \\(\\eta_1\\) are the 25th and 99th percentiles of \\(\\eta\\) respectively and \\(C_{a, b}\\) is the clamp function.</p> <p>This results in a score of 0 for common low intensity background regions, and 1 for high quality regions like cell nuclei.</p>"},{"location":"register/#extrapolation-in-z","title":"Extrapolation in z","text":"<p>The quality of the z-shifts drops rapidly towards the top end of the z-stack, because the optical flow uses windows of fixed radius (the <code>window_radius</code> parameter, which has default value 8). When these windows go over the edge of the image, the shifts get biased towards 0. This problem is made worse when the initial shift found is large in \\(z\\), as then the adjusted image is padded with many zeros.</p> <p>We get around this problem by linearly predicting the z-shifts from the bottom and middle of the image and replacing all z-shifts with these linear estimates. This is illustratedc in the figure below.</p> <p> Interpolation of x-y shifts, and extrapolation of z-shifts.  </p>"},{"location":"register/#iterative-closest-point","title":"Iterative Closest Point","text":"<p>We now attempt to find the affine corrections to the flows found earlier. As mentioned previously, this will be an affine transform for each tile \\(t\\), round \\(r\\) and channel \\(c\\). Furthermore, it will be separated into 2 transforms:</p> <ul> <li> <p>A round transform \\(B_{r}\\) which corrects for any errors in the flow \\(\\mathcal{F}_r\\),</p> </li> <li> <p>A channel transform \\(A_{c}\\) which corrects for all sources of the channel to channel variability.</p> </li> </ul> <p>We have omitted the tile subscript, but keep in the back of your mind that these transforms vary between tiles.</p>"},{"location":"register/#1-how-does-it-work_1","title":"1. How does it work","text":"<p>Optical flow took in 2 images (\\(I\\) and \\(J\\) ) as inputs and returned 3 images of the same size as outputs (the flow in each direction \\(y\\), \\(x\\) and \\(z\\)). ICP differs in that it takes in 2 point-clouds as input and returns an affine transform \\(A\\) as output. </p> <p>Let \\(X = \\begin{pmatrix} \\mathbf{x}_1, \\cdots,  \\mathbf{x}_m \\end{pmatrix}\\) be the base point cloud and \\(Y = \\begin{pmatrix} \\mathbf{y}_1, \\cdots,  \\mathbf{y}_n \\end{pmatrix}\\)  be the point cloud we are trying to match this to.</p> <p>In our case \\(X\\) is the set of anchor points and \\(Y\\) is the set of points in a given round and channel. So for every point \\(\\mathbf{y}_i\\) in \\(Y\\), we expect there to be a corresponding point \\(\\mathbf{x}_{\\beta(i)}\\) in \\(X\\) (the converse is not true). Estimating the matching \\(\\beta\\) between base and target points is the main difficulty in ICP. Some common methods to estimate this matching include:</p> <ol> <li> <p>We let \\(\\mathbf{x}_{\\beta(i)}\\) be the closest point from \\(X\\) to the point \\(\\mathbf{y}_i\\),</p> </li> <li> <p>The same as 1. but if there is no point in \\(X\\) within a certain radius \\(r\\) of \\(\\mathbf{y}_i\\) we don't bother to find a match,</p> </li> <li> <p>The same as 2. but we allow different radii in \\(y\\), \\(x\\) and \\(z\\). This is useful if we have some prior that the misalignment affects \\(y\\) and \\(x\\) more than \\(z\\), as we typically do.</p> </li> <li> <p>The same as 1. but we remove outliers where the shift \\(\\mathbf{y}_i -  \\mathbf{x}_{\\beta(i)}\\) seems to be very different from others in its vicinity.</p> </li> </ol> <p>We use approach 3. The parameters config parameters <code>neighb_dist_thresh_yx</code> and <code>neighb_dist_thresh_z</code> refer to \\(r_{yx}\\) and \\(r_z\\) respectively. </p> Setting \\(r_z\\) too low <p>Currently we think that ICP is correcting \\(y\\) and \\(x\\) more than \\(z\\), so we have \\(r_{z} &lt; r_{xy}\\). If this changes in the future (for example, if optical flow is not sufficiently capturing the variable z-shifts) then increasing \\(r_z\\) will allow ICP to have greater impact on the \\(z\\) transforms.</p> <p>Once we have a matching \\(\\beta\\), ICP works by finding an affine map \\(A\\) minimising the loss function </p> \\[ L(A) = \\sum_{i} || A \\mathbf{x}_{\\beta(i)} - \\mathbf{y}_i ||^2, \\] <p>(where the sum is over all those elements in \\(Y\\) that have been assigned a match) and then iterate this process of matching then minimising until some stopping criteria are met. We have the 2 following stopping criteria:</p> <ol> <li> <p>If 2 consecutive matchings are identical \\(\\beta_{t+1} = \\beta_t\\) then ICP gets stuck in an infinite loop, so we stop the iterations.</p> </li> <li> <p>The maximum number of iterations are reached. This is set by <code>icp_max_iter</code> which has default value 50.</p> </li> </ol> <p>The algorithm can be summarised as follows: <pre><code># Args:\n# X = m x 4 matrix (base positions padded)\n# Y = n x 3 matrix (target positions)\n# transform_initial = 4 x 3 initial transform\n# epsilon = distance threshold\n\n# Initialize\ntransform = transform_initial\nX = X @ transform\nneighb_prev = None\n\n# begin loop\nfor _ in range(n_iter):\n    # Find closest point in X to each point in Y\n    neighb = [argmin_k || X[k] - Y[j] || for j in range(n)]\n\n    # Remove these matches if they are above the neighb_dist_thresh\n    neighb = [neighb [j] if || X[neighb[j]] - Y[j] || &lt; epsilon, \n              else None for j in range(n)]\n\n    # Terminate if no change in neighbours\n    if neighb == neighb_prev:\n        QUIT\n\n    # Update transform\n    transform_update = argmin_B sum_j || X[neighb[j]] @ B - Y[j] || ** 2\n    X = X @ transform_update\n    transform = transform_update @ transform\n\n    # Update neighb_prev\n    neighb_prev = neighb\n</code></pre></p>"},{"location":"register/#2-implementation","title":"2. Implementation","text":"<p>Let \\(X_{r, c}\\) be the \\(n_{\\textrm{spots}}(r,c) \\times 3\\) matrix of all the spots found on round \\(r\\) channel \\(c\\).</p> Min Spots Criterion <p>ICP will not run on a tile, round, channel with too few spots. This threshold is set by <code>icp_min_spots</code> which has default value 100.</p>"},{"location":"register/#round-transform","title":"Round Transform","text":"<p>To compute the round transforms \\(B_r\\), we first adjust \\(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}\\) by the flow to yield \\(\\mathcal{F}_r(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}})\\), which should approximately put the anchor spots in round \\(r\\) coordinates. We align these to the target points \\(X_{r, c_{\\textrm{ref}}}\\). As a formula this reads as</p> \\[ B_r = \\textrm{ICP} (\\textrm{base} = \\mathcal{F}_r(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}), \\quad \\textrm{target} = X_{r, c_{\\textrm{ref}}}). \\] <p>This should capture any systematic affine errors in the flow field \\(\\mathcal{F}_r\\).</p>"},{"location":"register/#channel-transform","title":"Channel Transform","text":"<p>To compute the channel transforms \\(A_c\\) we align the anchor points \\(X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}\\) with all points in channel \\(c\\), regardless of round. We adjust these points to be in the anchor coordinate system. In a formula, this reads as</p> \\[ A_c = \\textrm{ICP} (\\textrm{base} = X_{r_{\\textrm{ref}}, c_{\\textrm{ref}}}, \\quad  \\textrm{target} = \\bigcup _r B_r ^{-1} (\\mathcal{F}_r ^{-1} (X_{r, c}))). \\] <p>The inverse transforms are used above because we are going from round \\(r\\) coordinates to round \\(r_{\\textrm{ref}}\\) coordinates, which is opposite to the way we computed the transforms.</p> <p>The chain of transforms is captured in the figure below:</p> <p>  Chain of transformations learnt for each round and channel. </p>"},{"location":"register/#diagnostics","title":"Diagnostics","text":"<p>Problems in registration can ruin several downstream analyses. These problems can be  diagnosed by looking at the Registration Viewer, as follows:</p> <pre><code>from coppafish import Notebook, RegistrationViewer\nnb_file = \"path/to/notebook\"\nnb = Notebook(nb_file)\nrv = RegistrationViewer(nb)\n</code></pre> <p>This will open a viewer with the following home screen:</p> <p>  The Registration Viewer  </p> <p>This shows the round registration on the top row and the channel registration on the bottom row. This is displayed as follows:</p> <ul> <li> <p>Each image in the top row shows a small patch of \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green. </p> </li> <li> <p>Each image in the bottom row shows a small patch of \\((r_{\\textrm{ref}}, c_{\\textrm{ref}})\\) in red, overlaid with \\((r_{\\textrm{mid}}, c)\\) in green.</p> </li> </ul> <p>Errors in registration may occur because of poor optical flow or ICP. The home screen shows small snippets of the images which indicate the overall quality of the registration. If these all look good, then the registration is likely fine. If not, then the options in the left panel will help diagnose the reason for poor round or channel registration.</p>"},{"location":"register/#different-methods","title":"Different Methods","text":"<p>There are 2 sliders at the bottom of the viewer. The z-slider allows you to move through the z-planes, while the method slider allows you to choose between different methods of displaying the images. The methods are as follows:</p> <ol> <li> <p>No Registration: This shows the images without any registration. This is useful to see how big the misalignments are.</p> </li> <li> <p>Optical Flow: This shows the images after the optical flow has been applied, but not the ICP transforms \\(A_{trc}\\). The channel transforms shown here use the optical flow plus the initial affine transform \\(\\tilde{A}_c\\) learnt from the fluorescent bead images.</p> </li> <li> <p>Optical Flow + ICP: This shows the images after the optical flow has been applied, and the ICP transforms \\(A_{trc}\\) have been applied. This is the final registration.</p> </li> </ol> <p>Registration with Different Methods</p> <p>The figures below show a good example of the different stages of round registration. The largest changes are made by optical flow, while ICP makes smaller corrections.</p> No RegistrationOptical FlowOptical Flow + ICP <p><p> </p></p> <p><p> </p></p> <p><p> </p></p> <p>The figures below show the different stages of channel registration. Here, image 1 is unregistered, image 2 is registered with optical flow and the initial affine transform, and image 3 is registered with optical flow and ICP. Most of the work done here is by ICP as the initial affine transform is not very good.</p> No RegistrationOptical Flow + Initial Affine TransformOptical Flow + ICP <p><p> </p></p> <p><p> </p></p> <p><p> </p></p>"},{"location":"register/#optical-flow-diagnostics","title":"Optical Flow Diagnostics","text":"<p>The Optical Flow Viewer can be selected on the left hand panel to view the optical flow fields for a particular round. This will open a screen like the one below:</p> <p>  The Optical Flow Viewer. </p> <p>This shows 3 columns of images:</p> <ol> <li> <p>No Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green before optical flow has been applied.</p> </li> <li> <p>Raw Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green after the raw flow has been applied. </p> </li> <li> <p>Smoothed Flow: This shows \\((r_{\\textrm{ref}}, c_{\\textrm{dapi}})\\) in red, overlaid with \\((r, c_{\\textrm{dapi}})\\) in green after the smoothed flow has been applied. </p> </li> </ol> <p>Rows 2, 3 and 4 show the raw and smooth flows in the \\(y\\), \\(x\\) and \\(z\\) directions respectively, while row 5 shows the correlation between the raw flow and the target image (this is the score \\(\\lambda(\\mathbf{x})\\) which is used to compute the smoothed flow).</p> <p>Optical Flow Viewer Example</p> <p>The figures below show an example of the different stages of optical flow. No flow shows a lot of misalignment. The raw flow shows the initial flow field, which is right in most places but wrong in others (particularly at edges). The smoothed flow is the final flow field, which is much better than the raw flow.</p> No FlowRaw FlowSmoothed Flow <p><p> </p></p> <p><p> </p></p> <p><p> </p></p> <p>The figure below is a closer look at the raw and smoothed flow fields, with the correlation plotted below them in blue.</p> <p><p> </p></p>"},{"location":"register/#icp-diagnostics","title":"ICP Diagnostics","text":"<p>Several diagnostics are available for ICP, and can be selected from the left hand panel. These viewers either show summary statistics or point clouds used to compute the transforms.</p>"},{"location":"register/#summary-statistics","title":"Summary Statistics","text":"<p>These show things like the average shift and scale for each round and channel and the convergence rates of each round and channel. This is useful for identifying outliers for some round or channel.</p> <p>Summary Statistics</p> <p>The figure below shows the shifts and scales of the ICP correction for each round and channel of a particular tile. These numbers alone do not tell us the whole picture about the affine transforms (for example they don't tell us about the rotation), but they can be useful for identifying outliers, and seeing how much work ICP is doing.</p> <p>In this image, very bright or very dark columns indicate large round corrections, while very bright or very dark rows indicate large channel corrections. Take note of the following points:</p> <ul> <li>The round corrections are largest in z. </li> <li>The channel corrections are largest in x and y.</li> <li>The channel scales and shifts are very similar in channels separated by a multiple of 4. This is because these channels come from the same camera, and therefore have roughly the same offset.</li> <li>Even though these scales are very small (around 1.003 at most), the images have size around 2000 pixels. This means that if we didn't correct for these scales, the images would be off by around 6 pixels, which is a lot.</li> </ul> <p><p> </p></p>"},{"location":"register/#point-clouds","title":"Point Clouds","text":"<p>These show the point clouds used to compute the round corrections \\(B_r\\) and channel corrections \\(A_c\\). This is much more detailed than the summary statistics and can be used to understand why convergence fails in certain cases.</p> <p>Point Clouds</p> <p>The figure below shows the point clouds used to compute the channel correction \\(A_c\\) for \\(c = 5\\). </p> <ul> <li>The white circles are the points from \\((r_{\\textrm{ref}}, c_{\\textrm{ref}})\\),</li> <li>the red crosses are the points from \\((r_{\\textrm{mid}}, c)\\). </li> <li>The cyan lines show the matches between points in the unaligned point clouds,</li> <li>the blue lines show the matches between points in the aligned point clouds. </li> <li>The yellow background image is bright in places where there are many matches and dark where there are few.</li> </ul> No RegistrationChannel Correction <p><p> </p></p> <p><p> </p></p> <p>The figure below shows the point clouds used to compute the round correction \\(B_r\\) for \\(r = 1\\). This viewer has the same components as the channel correction viewer but it defaults to showing all z-planes, as this is what ICP corrects for the most.</p> No RegistrationRound Correction <p><p> </p></p> <p><p> </p></p>"},{"location":"stitch/","title":"Stitch","text":"<p>The stitch section is the part of the pipeline responsible for creating a global coordinate system. This is done by looking at the overlapping regions between tiles and seeing how they have deviated from their expected positions.</p> <p> A Stitched collection of 6 tiles.  </p>"},{"location":"stitch/#algorithm","title":"Algorithm","text":"<p>The origin of each tile \\(t_i\\), which we call \\(\\mathbf{X}_i\\) is the position of its top left corner in the global coordinate system. Each tile \\(t_i\\) is given a nominal origin \\(\\mathbf{\\tilde{X}}_i\\) given by</p> \\[  \\mathbf{\\tilde{X}}_i = T(1-r) \\bigg( Y_i, X_i, 0 \\bigg), \\] <p>where </p> <ul> <li> <p>\\(T\\) is the size in pixels of the tile. We typically have \\(T = 2304\\),</p> </li> <li> <p>\\(r \\in (0, 1)\\) is the expected overlap between tiles and is chosen on the microscope,</p> </li> <li> <p>\\(Y_i\\) and \\(X_i\\) are the integer indices of the tile position in y and x respectively,</p> </li> <li> <p>we are using our default system of writing vectors in \\(yxz\\) format.</p> </li> </ul> <p>These origins are corrected by shifts \\(\\mathbf{S}_i\\) which capture small deviations from the nominal origins, ie:  \\(\\mathbf{X}_i = \\mathbf{\\tilde{X}}_i + \\mathbf{S}_i\\). These shifts are found as follows:</p> <ol> <li>     Compute shift $\\mathbf{v_{ij}}$ between the overlapping region of all adjacent tiles $t_i$ and $t_j$ using phase correlation. This would be $\\mathbf{0}$ if there were no deviations from the expected origins.   </li> <li>     Assign each shift $\\mathbf{v}_{ij}$ a score $\\lambda_{ij}$. We use       $$     \\lambda_{ij} = \\mathrm{corr}_ {\\mathbf{x}}(t_i(\\mathbf{x - v_{ij}}), t_j(\\mathbf{x}))^2.     $$   </li> <li>     We typically have about twice as many independent shifts as tiles (one south and one east for each non-boundary tile). This means our problem is over-constrained and doesn't have an exact solution. We can get an approximate solution for each shift $\\mathbf{S_i}$ by minimizing the loss function      $$     L(\\mathbf{S}) = \\sum_{i, j \\ \\mathrm{neighb}} \\lambda_{ij} |\\mathbf{S}_i - \\mathbf{S}_j - \\mathbf{v_{ij}}|^2,     $$      which is just saying that the deviations from the nominal origins for tiles $i$ and $j$ should be close to the observed deviations $\\mathbf{v_{ij}}$, and moreover that we should care more about making these similar when the deviations $\\mathbf{v_{ij}}$ are high quality, i.e., $\\lambda_{ij}$ is large.   </li> <li>     Differentiating the quadratic equation above gives a linear equation $\\mathbf{AS} = \\mathbf{B}$. However, $\\mathbf{A}$ is not invertible, so this does not have a unique solution (any common translation of all $\\mathbf{S}_i$ is another solution). We therefore solve for $\\mathbf{S}$ by minimizing a second loss function      $$     J(\\mathbf{S}) = ||\\mathbf{AS} - \\mathbf{B}||^2,     $$     which just says that we take the smallest of all the shifted solutions for $\\mathbf{S}$. This could have also been achieved by adding a regularization term $\\beta ||\\mathbf{S}||^2$ to the original loss function $L$.   </li> </ol>"},{"location":"stitch/#image-fusing","title":"Image Fusing","text":"<p>Once we have the final origins \\(\\mathbf{X}_i\\), we can fuse the images together. Overlapping regions are linearly tapered to avoid sharp transitions.</p> <p> Tapered edges can be seen clearly when some tiles finish in $z$ before others.  </p>"},{"location":"stitch/#global-coordinates-and-duplicate-spots","title":"Global Coordinates and Duplicate Spots","text":"<p>Each pixel \\(p\\) has local coordinate \\(\\mathbf{q}_p\\) which we can convert to global coordinates \\(\\mathbf{Q}_p\\)  by adding the origin of pixel \\(p\\)'s parent tile, ie:  \\(\\mathbf{Q}_p = \\mathbf{q}_p + \\mathbf{X}_{t(p)}\\). </p> <p>As discussed above, this is useful for viewing the spots in a global coordinate frame. It also allows us to remove duplicate spots at the overlap between tiles. This reduces computation time and ensures that no genes are double counted, which would skew the results of downstream analysis.</p> <p>When performing gene assignments, we only use the pixels \\(p\\) on tile \\(t\\) whose closest tile centre in global coordinates is tile \\(t\\). This takes care of duplicate spots in a way which doesn't actually have to view 2 spots overlapping in global coordinates, which would be error-prone.</p> <p> We only keep the spots on tile $t$ who are closer to the centre of $t$ than any other tile.  </p>"},{"location":"stitch/#diagnostics","title":"Diagnostics","text":""},{"location":"stitch/#view-stitch-checkerboard","title":"View Stitch Checkerboard","text":"<pre><code>from coppafish.plot.stitch import view_stitch_checkerboard\nview_stitch_checkerboard(nb)\n</code></pre> <p>This function plots tiles in an alternating green and red checkerboard pattern with overlapping regions in yellow.</p> <p> </p>"},{"location":"troubleshoot/","title":"Troubleshoot","text":""},{"location":"troubleshoot/#pipeline-crash","title":"Pipeline crash","text":"<p>If the coppafish pipeline is crashing, first read the error message. If there is a suggestion about how to fix the issue in the config, try changing the config variable and run the pipeline again. If the suggestion does not make sense to you, feel free to reach out to the developers for help or  create an issue on GitHub!</p>"},{"location":"troubleshoot/#notebook-will-not-open","title":"Notebook will not open","text":"<p>A notebook file can be corrupted if a process is killed while the notebook is being re-saved. When this happens, an error like:</p> <pre><code>TypeError: byte indices must be integers or slices, not tuple\n</code></pre> <p>will occur when trying to load the notebook. To fix this issue, delete the corrupted notebook, rename the backup notebook called <code>notebook_backup.npz</code> to the original notebook name and continue from there.</p>"},{"location":"troubleshoot/#cannot-open-napari-issues","title":"Cannot open napari issues","text":"<p>If napari fails to open and you see an error such as</p> <pre><code>WARNING: composeAndFlush: makeCurrent() failed\n</code></pre> <p>when trying to open the Viewer or RegistrationViewer, here are a few suggestions that might fix the issue:</p> <ul> <li>In the conda environment, run <code>conda install -c conda-forge libstdcxx-ng</code></li> <li>In the conda environment, run <code>conda install -c conda-forge libffi</code>.</li> </ul>"},{"location":"troubleshoot/#filter-image-clip-error","title":"Filter image clip error","text":"<p>An error can occur when a filtered image clips off too many pixels when trying to save. This happens because the filter step will scale up every non-DAPI image by a common factor to improve precision. There are two options to deal with this issue:</p> <ul> <li>Reduce image clipping by lowering <code>scale_multiplier</code> below the default value found in the <code>filter</code> config (the    default is found here).    After this, delete the <code>filter</code> directory found in the tiles directory and the <code>scale.txt</code>. Then, restart the pipeline.</li> <li>Follow a \"I don't care\" strategy by increasing <code>percent_clip_error</code> above the default to allow for more clipped    pixels. You can then restart the pipeline without deleting any files. If you wish to ignore warnings too, increase    <code>percent_clip_warn</code>.</li> </ul>"},{"location":"troubleshoot/#memory-crash-at-omp","title":"Memory crash at OMP","text":"<p>Try lowering <code>subset_size_xy</code> in the OMP config. This will cause OMP to compute on fewer pixels at time. It has a  minimal effect on compute times, but can lower the RAM/VRAM usage. The default is found  here.</p>"}]}